{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "511ef0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac8031e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r\"D:\\GUVI\\Mental_health_survey\\playground-series-s4e11\\train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2b1ff7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140700, 20)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "556a8c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 140700 entries, 0 to 140699\n",
      "Data columns (total 20 columns):\n",
      " #   Column                                 Non-Null Count   Dtype  \n",
      "---  ------                                 --------------   -----  \n",
      " 0   id                                     140700 non-null  int64  \n",
      " 1   Name                                   140700 non-null  object \n",
      " 2   Gender                                 140700 non-null  object \n",
      " 3   Age                                    140700 non-null  float64\n",
      " 4   City                                   140700 non-null  object \n",
      " 5   Working Professional or Student        140700 non-null  object \n",
      " 6   Profession                             104070 non-null  object \n",
      " 7   Academic Pressure                      27897 non-null   float64\n",
      " 8   Work Pressure                          112782 non-null  float64\n",
      " 9   CGPA                                   27898 non-null   float64\n",
      " 10  Study Satisfaction                     27897 non-null   float64\n",
      " 11  Job Satisfaction                       112790 non-null  float64\n",
      " 12  Sleep Duration                         140700 non-null  object \n",
      " 13  Dietary Habits                         140696 non-null  object \n",
      " 14  Degree                                 140698 non-null  object \n",
      " 15  Have you ever had suicidal thoughts ?  140700 non-null  object \n",
      " 16  Work/Study Hours                       140700 non-null  float64\n",
      " 17  Financial Stress                       140696 non-null  float64\n",
      " 18  Family History of Mental Illness       140700 non-null  object \n",
      " 19  Depression                             140700 non-null  int64  \n",
      "dtypes: float64(8), int64(2), object(10)\n",
      "memory usage: 21.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e17f88bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(r\"D:\\GUVI\\Mental_health_survey\\playground-series-s4e11\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8019769a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93800, 19)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1facb907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name ['Aaradhya' 'Vivan' 'Yuvraj' 'Rhea' 'Vani' 'Ritvik' 'Rajveer' 'Aishwarya'\n",
      " 'Simran' 'Utkarsh' 'Aahana' 'Tejas' 'Aadhya' 'Kiran' 'Aditi' 'Suhani'\n",
      " 'Jiya' 'Bhavesh' 'Armaan' 'Ishaani' 'Prachi' 'Pratyush' 'Abhinav'\n",
      " 'Siddhesh' 'Aditya' 'Aarav' 'Asha' 'Kashish' 'Prisha' 'Chhavi' 'Tanmay'\n",
      " 'Vihaan' 'Shiv' 'Anvi' 'Darsh' 'Samar' 'Raunak' 'Mahi' 'Shaurya' 'Vidya'\n",
      " 'Jai' 'Ayush' 'Ansh' 'Anand' 'Yashvi' 'Shrey' 'Ritika' 'Mihir' 'Isha'\n",
      " 'Arjun' 'Rohan' 'Pratham' 'Nirvaan' 'Ishaan' 'Aarya' 'Riya' 'Aariv'\n",
      " 'Raghavendra' 'Mahika' 'Abhishek' 'Harshil' 'Janvi' 'Kartikeya' 'Shivam'\n",
      " 'Advait' 'Reyansh' 'Saanvi' 'Ivaan' 'Pallavi' 'Sneha' 'Ayaan' 'Aakash'\n",
      " 'Raghav' 'Satyam' 'Aarush' 'Vibha' 'Rupal' 'Sanya' 'Mira' 'Rashi' 'Shlok'\n",
      " 'Harsha' 'Divya' 'Pranav' 'Hrithik' 'Tushar' 'Garima' 'Zoya' 'Kian'\n",
      " 'Navya' 'Lakshay' 'Kriti' 'Palak' 'Aryan' 'Parth' 'Ishan' 'Rupak'\n",
      " 'Atharv' 'Aarti' 'Anirudh' 'Kabir' 'Sanjeev' 'Sanket' 'Tara' 'Gagan'\n",
      " 'Anjali' 'Gaurav' 'Vikram' 'Yogesh' 'Ila' 'Rishi' 'Ayansh' 'Kolkata'\n",
      " 'Kavya' 'Aanchal' 'Vedant' 'Samaira' 'Harsh' 'Nikita' 'Charvi' 'Ishita'\n",
      " 'Ishwar' 'Kanika' 'Ritik' 'Rahil' 'Ira' 'Pari' 'Tanya' 'Yamini' 'Vidhi'\n",
      " 'Shreya' 'Neha' 'Esha' 'Damini' 'Manvi' 'Shivansh' 'Nikhil' 'Arya'\n",
      " 'Deepak' 'Shruti' 'Vrinda' 'Anushka' 'Sara' 'Zara' 'Gauri' 'Soham'\n",
      " 'Nandini' 'Siddharth' 'Rudransh' 'Manan' 'Dhruv' 'Tina' 'Pihu' 'Lavanya'\n",
      " 'Anika' 'Sai' 'Tanisha' 'Amit' 'Arav' 'Chirag' 'Krishna' 'Pooja' 'Eshita'\n",
      " 'Leela' 'Siddhi' 'Vanya' 'Trisha' 'Vivaan' 'Diya' 'Veda' 'Keshav' 'Kunal'\n",
      " 'Arnav' 'Barkha' 'Nalini' 'Golkut' 'Jasmine' 'Mithila' 'Rupa' 'Nisha'\n",
      " 'Saurav' 'Radhika' 'Jhanvi' 'Monika' 'Varun' 'Aan' 'Dev' 'Rajat' 'Naina'\n",
      " 'Nishant' 'Yash' 'Vaishnavi' 'Himani' 'Meera' 'Om' 'Anaya' 'Aniket'\n",
      " 'Tanvi' 'Mayank' 'Ishaesh' 'Srishti' 'Lata' 'Mukund' 'Ranveer' 'Khushi'\n",
      " 'Aarohi' 'Bhavna' 'Neil' 'Shivak' 'Apoorva' 'Kartik' 'Avni' 'Vaanya'\n",
      " 'Kush' 'Karishma' 'Shanaya' 'Virat' 'Rudra' 'A.Ed' 'Kiara' 'Krav' 'Ayhan'\n",
      " 'Nakul' 'Kalyan' 'Parvik' 'Vlaan' 'Harini' 'Mahak' 'Shivar' 'Abishma'\n",
      " 'Prvi' 'K. Kavya' 'Aieter' 'Aarsh' 'Aarvi' 'Kupa' 'Rudegrav' 'Parvi'\n",
      " 'Siddh' 'Rajankot' 'Ani' 'Rupil' 'Aarash' 'Taurav' 'Rani' 'Aanya' 'BE'\n",
      " 'Aavya' 'Raghavvi' 'Anarush' 'Aisha' 'Viv' 'Ronnie' '18' 'Rietal' 'R.Com'\n",
      " 'Anohi' 'Vivani' 'Ayash' 'Anil' 'Tarsh' 'Aiya' 'Patna' 'Tinmay' 'Rhesh'\n",
      " 'Shivna' 'Nikya' 'Arnar' 'Vakash' 'Jush' 'Randik' 'Siddir' 'Adachi'\n",
      " 'Anakash' 'Ayut' 'Pariv' 'Jhaan' 'Rai' 'Hreya' 'Shivivaam' 'Prishti'\n",
      " 'M.Com' 'Gavrachi' 'Rivaan' 'Haurav' 'Noreen' 'Anish' 'Shivan' 'Aniv'\n",
      " 'Aohi' 'Vashi' 'Aariket' 'Aarat' 'Vohi' 'Vavya' 'Hra' 'Ishaam' 'Anhil'\n",
      " 'Rieta' 'Zahra' 'Jathesh' 'Jhav' 'Anh' 'Vidvi' 'Raghavik' 'Mahir' 'Sansh'\n",
      " 'Shivvi' 'Prishant' 'Rupar' 'Eirini' 'Tanak' 'Researcher' 'Shaina' 'Aani'\n",
      " 'Plumber' 'Nanya' 'Manik' 'Nanchal' 'Ayoub' 'Aam' 'Airav' 'Zegmay'\n",
      " 'Aarsush' 'Vidra' 'Kani' 'Ishma' 'Naly' 'Jaish' 'Rajya' 'Chrinda' 'Tani'\n",
      " 'Harshand' 'Ranchal' 'Vita' 'Prandini' 'Mahav' 'Nhanini' 'Anupal' 'Manr'\n",
      " 'Eikram' 'Arsha' 'Kartika' 'Pradhya' 'Harshir' 'Shivlok' 'Shivwar'\n",
      " 'Abarav' 'Ayya' 'Rupai' 'Rudrithik' 'Varanasi' 'K.Pharm' 'UX/UI Designer'\n",
      " 'Ariti' 'Manjun' 'Arvik' 'Thane' 'Rupika' 'Aaransh' 'Ijra' 'Anar' 'Parha'\n",
      " 'Vidha' 'Prayat' 'Yurav' 'Srinagar' 'Aaranya' 'Rupadhya' 'Anishi'\n",
      " 'Aikash' 'Nhanvi' 'Jiram' 'Rudrey' 'Shashi' 'Anya' 'Eisha' 'Vhaani'\n",
      " 'Prilak' 'Aarani' 'Nya' 'Harshav' 'Ewesh' 'Aanket' 'Tohar' 'Ryouvik'\n",
      " 'Niya' 'Anjun' 'Rupat' 'Anahk' 'Shivsh' 'Niki' 'Nishita' 'Rohik' 'Prishi'\n",
      " 'Ishaansh' 'Virar' 'Sharth' 'M.Tech' 'Shir' 'Kike' 'Shivvaan' 'Aarla'\n",
      " 'Nishi' 'Aarand' 'Adiya' 'Ritak' 'Kashi' 'Krey' 'Prarav' 'Kartal'\n",
      " 'Anariv' 'Irit' 'Kanisha' 'Anisha' 'Harshaun' 'Rietvik' 'Vasai-Virar'\n",
      " 'Ishlok' 'Vika' 'Rika' 'Aarun']\n",
      "Gender ['Female' 'Male']\n",
      "City ['Ludhiana' 'Varanasi' 'Visakhapatnam' 'Mumbai' 'Kanpur' 'Ahmedabad'\n",
      " 'Thane' 'Nashik' 'Bangalore' 'Patna' 'Rajkot' 'Jaipur' 'Pune' 'Lucknow'\n",
      " 'Meerut' 'Agra' 'Surat' 'Faridabad' 'Hyderabad' 'Srinagar' 'Ghaziabad'\n",
      " 'Kolkata' 'Chennai' 'Kalyan' 'Nagpur' 'Vadodara' 'Vasai-Virar' 'Delhi'\n",
      " 'Bhopal' 'Indore' 'Ishanabad' 'Vidhi' 'Ayush' 'Gurgaon' 'Krishna'\n",
      " 'Aishwarya' 'Keshav' 'Harsha' 'Nalini' 'Aditya' 'Malyansh' 'Raghavendra'\n",
      " 'Saanvi' 'M.Tech' 'Bhavna' 'Less Delhi' 'Nandini' 'M.Com' 'Plata'\n",
      " 'Atharv' 'Pratyush' 'City' '3.0' 'Less than 5 Kalyan' 'MCA' 'Mira'\n",
      " 'Moreadhyay' 'Morena' 'Ishkarsh' 'Kashk' 'Mihir' 'Vidya' 'Tolkata' 'Anvi'\n",
      " 'Krinda' 'Ayansh' 'Shrey' 'Ivaan' 'Vaanya' 'Gaurav' 'Harsh' 'Reyansh'\n",
      " 'Kashish' 'Kibara' 'Vaishnavi' 'Chhavi' 'Parth' 'Mahi' 'Tushar' 'MSc'\n",
      " 'No' 'Rashi' 'ME' 'Molkata' 'Researcher' 'Kagan' 'Armaan' 'Ithal'\n",
      " 'Nalyan' 'Dhruv' 'Galesabad' 'Itheg' 'Aaradhya' 'Pooja' 'Khushi'\n",
      " 'Khaziabad' 'Jhanvi' 'Unirar']\n",
      "Working Professional or Student ['Working Professional' 'Student']\n",
      "Profession ['Chef' 'Teacher' nan 'Business Analyst' 'Finanancial Analyst' 'Chemist'\n",
      " 'Electrician' 'Software Engineer' 'Data Scientist' 'Plumber'\n",
      " 'Marketing Manager' 'Accountant' 'Entrepreneur' 'HR Manager'\n",
      " 'UX/UI Designer' 'Content Writer' 'Educational Consultant'\n",
      " 'Civil Engineer' 'Manager' 'Pharmacist' 'Financial Analyst' 'Architect'\n",
      " 'Mechanical Engineer' 'Customer Support' 'Consultant' 'Judge'\n",
      " 'Researcher' 'Pilot' 'Graphic Designer' 'Travel Consultant'\n",
      " 'Digital Marketer' 'Lawyer' 'Research Analyst' 'Sales Executive' 'Doctor'\n",
      " 'Unemployed' 'Investment Banker' 'Family Consultant' 'B.Com' 'BE'\n",
      " 'Student' 'Yogesh' 'Dev' 'MBA' 'LLM' 'BCA' 'Academic' 'Profession'\n",
      " 'FamilyVirar' 'City Manager' 'BBA' 'Medical Doctor'\n",
      " 'Working Professional' 'MBBS' 'Patna' 'Unveil' 'B.Ed' 'Nagpur' 'Moderate'\n",
      " 'M.Ed' 'Analyst' 'Pranav' 'Visakhapatnam' 'PhD' 'Yuvraj']\n",
      "Sleep Duration ['More than 8 hours' 'Less than 5 hours' '5-6 hours' '7-8 hours'\n",
      " 'Sleep_Duration' '1-2 hours' '6-8 hours' '4-6 hours' '6-7 hours'\n",
      " '10-11 hours' '8-9 hours' '40-45 hours' '9-11 hours' '2-3 hours'\n",
      " '3-4 hours' 'Moderate' '55-66 hours' '4-5 hours' '9-6 hours' '1-3 hours'\n",
      " 'Indore' '45' '1-6 hours' '35-36 hours' '8 hours' 'No' '10-6 hours'\n",
      " 'than 5 hours' '49 hours' 'Unhealthy' 'Work_Study_Hours' '3-6 hours'\n",
      " '45-48 hours' '9-5' 'Pune' '9-5 hours']\n",
      "Dietary Habits ['Healthy' 'Unhealthy' 'Moderate' 'Yes' 'Pratham' 'BSc' 'Gender' '3'\n",
      " 'More Healthy' 'Less than Healthy' 'Mihir' '1.0' 'Hormonal' 'Electrician'\n",
      " nan 'No Healthy' 'Less Healthy' 'M.Tech' 'Vegas' 'No' 'Male' 'Indoor'\n",
      " 'Class 12' '2']\n",
      "Degree ['BHM' 'LLB' 'B.Pharm' 'BBA' 'MCA' 'MD' 'BSc' 'ME' 'B.Arch' 'BCA' 'BE'\n",
      " 'MA' 'B.Ed' 'B.Com' 'MBA' 'M.Com' 'MHM' 'BA' 'Class 12' 'M.Tech' 'PhD'\n",
      " 'M.Ed' 'MSc' 'B.Tech' 'LLM' 'MBBS' 'M.Pharm' 'UX/UI Designer' 'MPA' 'BH'\n",
      " 'Nalini' 'BEd' 'B.Sc' 'Veda' 'Bhopal' 'S.Tech' 'Degree' '20' 'Class 11'\n",
      " 'H_Pharm' 'M' 'P.Com' 'BPharm' 'Business Analyst' 'M.Arch' 'LL.Com'\n",
      " 'Data Scientist' 'MPharm' 'L.Ed' 'P.Pharm' 'Kalyan' 'Unite' 'BArch'\n",
      " 'HR Manager' 'Badhya' 'S.Pharm' 'LLBA' 'Vrinda' 'M. Business Analyst'\n",
      " 'Bhavesh' '0' 'LLCom' '29' 'MTech' 'Vivaan' 'BPA' 'Plumber' '5.61' 'Brit'\n",
      " 'B.03' 'Ritik' '5.56' 'MEd' 'B' 'B BA' '7.06' 'B.B.Arch' 'ACA' 'Brithika'\n",
      " 'CGPA' '24' 'M_Tech' 'Pihu' 'BB' 'Jhanvi' 'LLTech' 'Aarav' 'Entrepreneur'\n",
      " '8.56' 'LHM' 'Lata' 'S.Arch' 'Marsh' 'HCA' '5.88' 'B.Student' 'LL B.Ed'\n",
      " 'M.S' 'Navya' 'Mahika' nan 'K.Ed' 'B.3.79' 'Mthanya'\n",
      " 'Working Professional' 'Esha' 'LLS' 'LLEd' 'E.Tech' 'Doctor' 'N.Pharm'\n",
      " 'LCA' 'B B.Com' 'RCA' 'Mihir' 'Advait']\n",
      "Have you ever had suicidal thoughts ? ['No' 'Yes']\n",
      "Family History of Mental Illness ['No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "for i in df_train.select_dtypes(include = [\"object\"]).columns:\n",
    "\t\t\t print(i, df_train[i].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04953555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec83dc85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                            0\n",
       "Name                                          0\n",
       "Gender                                        0\n",
       "Age                                           0\n",
       "City                                          0\n",
       "Working Professional or Student               0\n",
       "Profession                                36630\n",
       "Academic Pressure                        112803\n",
       "Work Pressure                             27918\n",
       "CGPA                                     112802\n",
       "Study Satisfaction                       112803\n",
       "Job Satisfaction                          27910\n",
       "Sleep Duration                                0\n",
       "Dietary Habits                                4\n",
       "Degree                                        2\n",
       "Have you ever had suicidal thoughts ?         0\n",
       "Work/Study Hours                              0\n",
       "Financial Stress                              4\n",
       "Family History of Mental Illness              0\n",
       "Depression                                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c84e6516",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_cities = {\n",
    "    \"Ishanabad\",\"Vidhi\",\"Ayush\",\"Krishna\",\"Aishwarya\",\"Keshav\",\"Harsha\",\"Nalini\",\"Aditya\",\"Malyansh\",\n",
    "    \"Raghavendra\",\"Saanvi\",\"Bhavna\",\"Nandini\",\"Atharv\",\"Pratyush\",\"Mira\",\"Mihir\",\"Vidya\",\"Anvi\",\n",
    "    \"Krinda\",\"Ayansh\",\"Shrey\",\"Ivaan\",\"Vaanya\",\"Gaurav\",\"Harsh\",\"Reyansh\",\"Kashish\",\"Kibara\",\n",
    "    \"Vaishnavi\",\"Chhavi\",\"Parth\",\"Mahi\",\"Tushar\",\"Rashi\",\"Armaan\",\"Aaradhya\",\"Pooja\",\"Khushi\",\n",
    "    \"Jhanvi\",\"M.Tech\",\"M.Com\",\"MCA\",\"MSc\",\"ME\",\"City\",\"3.0\",\"No\",\"Less Delhi\",\"Less than 5 Kalyan\",\n",
    "    \"Moreadhyay\",\"Researcher\",\"Kagan\",\"Ithal\",\"Galesabad\",\"Itheg\",\"Unirar\"\n",
    "}\n",
    "invalid_cities.update([\"Plata\", \"Ishkarsh\", \"Kashk\", \"Dhruv\"])\n",
    "\n",
    "df_train['City'] = df_train['City'].apply(lambda x: \"Unknown\" if x in invalid_cities else x)\n",
    "\n",
    "city_corrections = {\n",
    "    \"Tolkata\": \"Kolkata\",\n",
    "    \"Molkata\": \"Kolkata\",\n",
    "    \"Khaziabad\": \"Ghaziabad\",\n",
    "    \"Nalyan\": \"Kalyan\"\n",
    "}\n",
    "\n",
    "df_train['City'] = df_train['City'].replace(city_corrections)\n",
    "df_train = df_train.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe0fc72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ludhiana', 'Varanasi', 'Visakhapatnam', 'Mumbai', 'Kanpur',\n",
       "       'Ahmedabad', 'Thane', 'Nashik', 'Bangalore', 'Patna', 'Rajkot',\n",
       "       'Jaipur', 'Pune', 'Lucknow', 'Meerut', 'Agra', 'Surat',\n",
       "       'Faridabad', 'Hyderabad', 'Srinagar', 'Ghaziabad', 'Kolkata',\n",
       "       'Chennai', 'Kalyan', 'Nagpur', 'Vadodara', 'Vasai-Virar', 'Delhi',\n",
       "       'Bhopal', 'Indore', 'Unknown', 'Gurgaon', 'Morena'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"City\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "936cfdc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140700, 20)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7978d057",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_professions = [\n",
    "    \"B.Com\", \"BE\", \"MBA\", \"LLM\", \"BCA\", \"BBA\", \"MBBS\", \"B.Ed\", \"M.Ed\", \"PhD\",\n",
    "    \"Student\", \"Working Professional\", \"Academic\", \"Profession\",\n",
    "    \"Yogesh\", \"Dev\", \"Pranav\", \"Yuvraj\",\n",
    "    \"FamilyVirar\", \"City Manager\", \"Patna\", \"Nagpur\",\n",
    "    \"Unveil\", \"Moderate\",\n",
    "    \"Visakhapatnam\"\n",
    "]\n",
    "\n",
    "df_train['Profession'] = df_train['Profession'].apply(lambda x: \"Unknown\" if x in invalid_professions else x)\n",
    "\n",
    "profession_corrections = {\n",
    "    \"Finanancial Analyst\": \"Financial Analyst\",\n",
    "    \"Medical Doctor\": \"Doctor\"\n",
    "}\n",
    "\n",
    "df_train['Profession'] = df_train['Profession'].replace(profession_corrections)\n",
    "df_train = df_train.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e47e1703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Chef', 'Teacher', nan, 'Business Analyst', 'Financial Analyst',\n",
       "       'Chemist', 'Electrician', 'Software Engineer', 'Data Scientist',\n",
       "       'Plumber', 'Marketing Manager', 'Accountant', 'Entrepreneur',\n",
       "       'HR Manager', 'UX/UI Designer', 'Content Writer',\n",
       "       'Educational Consultant', 'Civil Engineer', 'Manager',\n",
       "       'Pharmacist', 'Architect', 'Mechanical Engineer',\n",
       "       'Customer Support', 'Consultant', 'Judge', 'Researcher', 'Pilot',\n",
       "       'Graphic Designer', 'Travel Consultant', 'Digital Marketer',\n",
       "       'Lawyer', 'Research Analyst', 'Sales Executive', 'Doctor',\n",
       "       'Unemployed', 'Investment Banker', 'Family Consultant', 'Unknown',\n",
       "       'Analyst'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"Profession\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aae9c382",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_sleep = [\n",
    "    'Sleep_Duration', 'Indore', 'Pune', 'Moderate', 'Unhealthy', 'No', \n",
    "    'Work_Study_Hours', '45', '49 hours', '35-36 hours', '55-66 hours',\n",
    "    '9-6 hours', '10-6 hours', '9-5', '9-5 hours',\n",
    "    '40-45 hours', '45-48 hours', '1-6 hours'\n",
    "]\n",
    "\n",
    "sleep_corrections = {\n",
    "    'than 5 hours': 'Less than 5 hours',\n",
    "    '8 hours': '7-8 hours'\n",
    "}\n",
    "\n",
    "df_train['Sleep Duration'] = df_train['Sleep Duration'].apply(\n",
    "    lambda x: 'Unknown' if x in invalid_sleep or pd.isna(x) else x\n",
    ")\n",
    "\n",
    "df_train['Sleep Duration'] = df_train['Sleep Duration'].replace(sleep_corrections)\n",
    "\n",
    "def standardize_sleep_duration(val):\n",
    "    if pd.isna(val) or val.lower() == 'unknown':\n",
    "        return 'Unknown'\n",
    "    val = val.strip().lower()\n",
    "    if val in ['less than 5 hours', '1-2 hours', '1-3 hours', '2-3 hours',\n",
    "               '3-4 hours', '3-6 hours', '4-5 hours', '4-6 hours']:\n",
    "        return '<5 hours'\n",
    "    elif val == '5-6 hours':\n",
    "        return '5-6 hours'\n",
    "    elif val == '6-7 hours':\n",
    "        return '6-7 hours'\n",
    "    elif val == '6-8 hours':\n",
    "        return '6-8 hours'   \n",
    "    elif val == '7-8 hours':\n",
    "        return '7-8 hours'\n",
    "    elif val in ['8-9 hours', 'more than 8 hours']:\n",
    "        return '8-9 hours'\n",
    "    elif val in ['9-11 hours', '10-11 hours']:\n",
    "        return '9-11 hours'\n",
    "    else:\n",
    "        return val\n",
    "\n",
    "df_train['Sleep Duration'] = df_train['Sleep Duration'].apply(standardize_sleep_duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6657e804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['8-9 hours', '<5 hours', '5-6 hours', '7-8 hours', 'Unknown',\n",
       "       '6-8 hours', '6-7 hours', '9-11 hours'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"Sleep Duration\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f46b85f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140700, 20)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d450548",
   "metadata": {},
   "outputs": [],
   "source": [
    "diet_corrections = {\n",
    "    \"No Healthy\": \"Unhealthy\",\n",
    "    \"Less Healthy\": \"Unhealthy\",\n",
    "    \"More Healthy\": \"Healthy\",\n",
    "    \"Less than Healthy\": \"Unhealthy\"\n",
    "}\n",
    "\n",
    "invalid_diet = [\n",
    "    \"Yes\", \"No\", \"Pratham\", \"Mihir\", \"BSc\", \"M.Tech\", \"Class 12\",\n",
    "    \"Gender\", \"Male\", \"3\", \"1.0\", \"2\", \"Hormonal\", \"Electrician\",\n",
    "    \"Vegas\", \"Indoor\"\n",
    "]\n",
    "\n",
    "df_train['Dietary Habits'] = df_train['Dietary Habits'].apply(\n",
    "    lambda x: \"Unknown\" if x in invalid_diet else x\n",
    ")\n",
    "\n",
    "df_train['Dietary Habits'] = df_train['Dietary Habits'].replace(diet_corrections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00fbe655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Healthy', 'Unhealthy', 'Moderate', 'Unknown', nan], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"Dietary Habits\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "899181c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name ['Aaradhya' 'Vivan' 'Yuvraj' 'Rhea' 'Vani' 'Ritvik' 'Rajveer' 'Aishwarya'\n",
      " 'Simran' 'Utkarsh' 'Aahana' 'Tejas' 'Aadhya' 'Kiran' 'Aditi' 'Suhani'\n",
      " 'Jiya' 'Bhavesh' 'Armaan' 'Ishaani' 'Prachi' 'Pratyush' 'Abhinav'\n",
      " 'Siddhesh' 'Aditya' 'Aarav' 'Asha' 'Kashish' 'Prisha' 'Chhavi' 'Tanmay'\n",
      " 'Vihaan' 'Shiv' 'Anvi' 'Darsh' 'Samar' 'Raunak' 'Mahi' 'Shaurya' 'Vidya'\n",
      " 'Jai' 'Ayush' 'Ansh' 'Anand' 'Yashvi' 'Shrey' 'Ritika' 'Mihir' 'Isha'\n",
      " 'Arjun' 'Rohan' 'Pratham' 'Nirvaan' 'Ishaan' 'Aarya' 'Riya' 'Aariv'\n",
      " 'Raghavendra' 'Mahika' 'Abhishek' 'Harshil' 'Janvi' 'Kartikeya' 'Shivam'\n",
      " 'Advait' 'Reyansh' 'Saanvi' 'Ivaan' 'Pallavi' 'Sneha' 'Ayaan' 'Aakash'\n",
      " 'Raghav' 'Satyam' 'Aarush' 'Vibha' 'Rupal' 'Sanya' 'Mira' 'Rashi' 'Shlok'\n",
      " 'Harsha' 'Divya' 'Pranav' 'Hrithik' 'Tushar' 'Garima' 'Zoya' 'Kian'\n",
      " 'Navya' 'Lakshay' 'Kriti' 'Palak' 'Aryan' 'Parth' 'Ishan' 'Rupak'\n",
      " 'Atharv' 'Aarti' 'Anirudh' 'Kabir' 'Sanjeev' 'Sanket' 'Tara' 'Gagan'\n",
      " 'Anjali' 'Gaurav' 'Vikram' 'Yogesh' 'Ila' 'Rishi' 'Ayansh' 'Kolkata'\n",
      " 'Kavya' 'Aanchal' 'Vedant' 'Samaira' 'Harsh' 'Nikita' 'Charvi' 'Ishita'\n",
      " 'Ishwar' 'Kanika' 'Ritik' 'Rahil' 'Ira' 'Pari' 'Tanya' 'Yamini' 'Vidhi'\n",
      " 'Shreya' 'Neha' 'Esha' 'Damini' 'Manvi' 'Shivansh' 'Nikhil' 'Arya'\n",
      " 'Deepak' 'Shruti' 'Vrinda' 'Anushka' 'Sara' 'Zara' 'Gauri' 'Soham'\n",
      " 'Nandini' 'Siddharth' 'Rudransh' 'Manan' 'Dhruv' 'Tina' 'Pihu' 'Lavanya'\n",
      " 'Anika' 'Sai' 'Tanisha' 'Amit' 'Arav' 'Chirag' 'Krishna' 'Pooja' 'Eshita'\n",
      " 'Leela' 'Siddhi' 'Vanya' 'Trisha' 'Vivaan' 'Diya' 'Veda' 'Keshav' 'Kunal'\n",
      " 'Arnav' 'Barkha' 'Nalini' 'Golkut' 'Jasmine' 'Mithila' 'Rupa' 'Nisha'\n",
      " 'Saurav' 'Radhika' 'Jhanvi' 'Monika' 'Varun' 'Aan' 'Dev' 'Rajat' 'Naina'\n",
      " 'Nishant' 'Yash' 'Vaishnavi' 'Himani' 'Meera' 'Om' 'Anaya' 'Aniket'\n",
      " 'Tanvi' 'Mayank' 'Ishaesh' 'Srishti' 'Lata' 'Mukund' 'Ranveer' 'Khushi'\n",
      " 'Aarohi' 'Bhavna' 'Neil' 'Shivak' 'Apoorva' 'Kartik' 'Avni' 'Vaanya'\n",
      " 'Kush' 'Karishma' 'Shanaya' 'Virat' 'Rudra' 'A.Ed' 'Kiara' 'Krav' 'Ayhan'\n",
      " 'Nakul' 'Kalyan' 'Parvik' 'Vlaan' 'Harini' 'Mahak' 'Shivar' 'Abishma'\n",
      " 'Prvi' 'K. Kavya' 'Aieter' 'Aarsh' 'Aarvi' 'Kupa' 'Rudegrav' 'Parvi'\n",
      " 'Siddh' 'Rajankot' 'Ani' 'Rupil' 'Aarash' 'Taurav' 'Rani' 'Aanya' 'BE'\n",
      " 'Aavya' 'Raghavvi' 'Anarush' 'Aisha' 'Viv' 'Ronnie' '18' 'Rietal' 'R.Com'\n",
      " 'Anohi' 'Vivani' 'Ayash' 'Anil' 'Tarsh' 'Aiya' 'Patna' 'Tinmay' 'Rhesh'\n",
      " 'Shivna' 'Nikya' 'Arnar' 'Vakash' 'Jush' 'Randik' 'Siddir' 'Adachi'\n",
      " 'Anakash' 'Ayut' 'Pariv' 'Jhaan' 'Rai' 'Hreya' 'Shivivaam' 'Prishti'\n",
      " 'M.Com' 'Gavrachi' 'Rivaan' 'Haurav' 'Noreen' 'Anish' 'Shivan' 'Aniv'\n",
      " 'Aohi' 'Vashi' 'Aariket' 'Aarat' 'Vohi' 'Vavya' 'Hra' 'Ishaam' 'Anhil'\n",
      " 'Rieta' 'Zahra' 'Jathesh' 'Jhav' 'Anh' 'Vidvi' 'Raghavik' 'Mahir' 'Sansh'\n",
      " 'Shivvi' 'Prishant' 'Rupar' 'Eirini' 'Tanak' 'Researcher' 'Shaina' 'Aani'\n",
      " 'Plumber' 'Nanya' 'Manik' 'Nanchal' 'Ayoub' 'Aam' 'Airav' 'Zegmay'\n",
      " 'Aarsush' 'Vidra' 'Kani' 'Ishma' 'Naly' 'Jaish' 'Rajya' 'Chrinda' 'Tani'\n",
      " 'Harshand' 'Ranchal' 'Vita' 'Prandini' 'Mahav' 'Nhanini' 'Anupal' 'Manr'\n",
      " 'Eikram' 'Arsha' 'Kartika' 'Pradhya' 'Harshir' 'Shivlok' 'Shivwar'\n",
      " 'Abarav' 'Ayya' 'Rupai' 'Rudrithik' 'Varanasi' 'K.Pharm' 'UX/UI Designer'\n",
      " 'Ariti' 'Manjun' 'Arvik' 'Thane' 'Rupika' 'Aaransh' 'Ijra' 'Anar' 'Parha'\n",
      " 'Vidha' 'Prayat' 'Yurav' 'Srinagar' 'Aaranya' 'Rupadhya' 'Anishi'\n",
      " 'Aikash' 'Nhanvi' 'Jiram' 'Rudrey' 'Shashi' 'Anya' 'Eisha' 'Vhaani'\n",
      " 'Prilak' 'Aarani' 'Nya' 'Harshav' 'Ewesh' 'Aanket' 'Tohar' 'Ryouvik'\n",
      " 'Niya' 'Anjun' 'Rupat' 'Anahk' 'Shivsh' 'Niki' 'Nishita' 'Rohik' 'Prishi'\n",
      " 'Ishaansh' 'Virar' 'Sharth' 'M.Tech' 'Shir' 'Kike' 'Shivvaan' 'Aarla'\n",
      " 'Nishi' 'Aarand' 'Adiya' 'Ritak' 'Kashi' 'Krey' 'Prarav' 'Kartal'\n",
      " 'Anariv' 'Irit' 'Kanisha' 'Anisha' 'Harshaun' 'Rietvik' 'Vasai-Virar'\n",
      " 'Ishlok' 'Vika' 'Rika' 'Aarun']\n",
      "Gender ['Female' 'Male']\n",
      "City ['Ludhiana' 'Varanasi' 'Visakhapatnam' 'Mumbai' 'Kanpur' 'Ahmedabad'\n",
      " 'Thane' 'Nashik' 'Bangalore' 'Patna' 'Rajkot' 'Jaipur' 'Pune' 'Lucknow'\n",
      " 'Meerut' 'Agra' 'Surat' 'Faridabad' 'Hyderabad' 'Srinagar' 'Ghaziabad'\n",
      " 'Kolkata' 'Chennai' 'Kalyan' 'Nagpur' 'Vadodara' 'Vasai-Virar' 'Delhi'\n",
      " 'Bhopal' 'Indore' 'Unknown' 'Gurgaon' 'Morena']\n",
      "Working Professional or Student ['Working Professional' 'Student']\n",
      "Profession ['Chef' 'Teacher' nan 'Business Analyst' 'Financial Analyst' 'Chemist'\n",
      " 'Electrician' 'Software Engineer' 'Data Scientist' 'Plumber'\n",
      " 'Marketing Manager' 'Accountant' 'Entrepreneur' 'HR Manager'\n",
      " 'UX/UI Designer' 'Content Writer' 'Educational Consultant'\n",
      " 'Civil Engineer' 'Manager' 'Pharmacist' 'Architect' 'Mechanical Engineer'\n",
      " 'Customer Support' 'Consultant' 'Judge' 'Researcher' 'Pilot'\n",
      " 'Graphic Designer' 'Travel Consultant' 'Digital Marketer' 'Lawyer'\n",
      " 'Research Analyst' 'Sales Executive' 'Doctor' 'Unemployed'\n",
      " 'Investment Banker' 'Family Consultant' 'Unknown' 'Analyst']\n",
      "Sleep Duration ['8-9 hours' '<5 hours' '5-6 hours' '7-8 hours' 'Unknown' '6-8 hours'\n",
      " '6-7 hours' '9-11 hours']\n",
      "Dietary Habits ['Healthy' 'Unhealthy' 'Moderate' 'Unknown' nan]\n",
      "Degree ['BHM' 'LLB' 'B.Pharm' 'BBA' 'MCA' 'MD' 'BSc' 'ME' 'B.Arch' 'BCA' 'BE'\n",
      " 'MA' 'B.Ed' 'B.Com' 'MBA' 'M.Com' 'MHM' 'BA' 'Class 12' 'M.Tech' 'PhD'\n",
      " 'M.Ed' 'MSc' 'B.Tech' 'LLM' 'MBBS' 'M.Pharm' 'UX/UI Designer' 'MPA' 'BH'\n",
      " 'Nalini' 'BEd' 'B.Sc' 'Veda' 'Bhopal' 'S.Tech' 'Degree' '20' 'Class 11'\n",
      " 'H_Pharm' 'M' 'P.Com' 'BPharm' 'Business Analyst' 'M.Arch' 'LL.Com'\n",
      " 'Data Scientist' 'MPharm' 'L.Ed' 'P.Pharm' 'Kalyan' 'Unite' 'BArch'\n",
      " 'HR Manager' 'Badhya' 'S.Pharm' 'LLBA' 'Vrinda' 'M. Business Analyst'\n",
      " 'Bhavesh' '0' 'LLCom' '29' 'MTech' 'Vivaan' 'BPA' 'Plumber' '5.61' 'Brit'\n",
      " 'B.03' 'Ritik' '5.56' 'MEd' 'B' 'B BA' '7.06' 'B.B.Arch' 'ACA' 'Brithika'\n",
      " 'CGPA' '24' 'M_Tech' 'Pihu' 'BB' 'Jhanvi' 'LLTech' 'Aarav' 'Entrepreneur'\n",
      " '8.56' 'LHM' 'Lata' 'S.Arch' 'Marsh' 'HCA' '5.88' 'B.Student' 'LL B.Ed'\n",
      " 'M.S' 'Navya' 'Mahika' nan 'K.Ed' 'B.3.79' 'Mthanya'\n",
      " 'Working Professional' 'Esha' 'LLS' 'LLEd' 'E.Tech' 'Doctor' 'N.Pharm'\n",
      " 'LCA' 'B B.Com' 'RCA' 'Mihir' 'Advait']\n",
      "Have you ever had suicidal thoughts ? ['No' 'Yes']\n",
      "Family History of Mental Illness ['No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "for i in df_train.select_dtypes(include = [\"object\"]).columns:\n",
    "\t\t\t print(i, df_train[i].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ab6140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_train.select_dtypes(include=['object']).columns:\n",
    "    df_train[col] = df_train[col].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "301c0231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140700, 20)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a427bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_corrections = {\n",
    "        'BEd': 'B.Ed',\n",
    "        'MEd': 'M.Ed',\n",
    "        'MTech': 'M.Tech',\n",
    "        'M_Tech': 'M.Tech',\n",
    "        'BArch': 'B.Arch',\n",
    "        'B BA': 'BBA',\n",
    "        'B B.Com': 'B.Com',\n",
    "        'BSc': 'B.Sc',\n",
    "        'MSc': 'M.Sc',\n",
    "        'PhD': 'Ph.D',\n",
    "        'MPharm': 'M.Pharm',\n",
    "        'BPharm': 'B.Pharm',\n",
    "        'LLCom': 'LL.Com',\n",
    "        'LLBA': 'LL.B',\n",
    "        'BCA': 'B.C.A',\n",
    "        'MCA': 'M.C.A',\n",
    "        'MBA': 'M.B.A'\n",
    "    }\n",
    "\n",
    "df_train['Degree'] = df_train['Degree'].replace(degree_corrections)\n",
    "\n",
    "invalid_degrees = [\n",
    "        'Nalini','Veda','Bhopal','Degree','20','H_Pharm','M','P.Com',\n",
    "        'Business Analyst','Data Scientist','Unite','HR Manager','Badhya',\n",
    "        'S.Pharm','Vrinda','M. Business Analyst','Bhavesh','0','29','Vivaan',\n",
    "        'BPA','Plumber','5.61','Brit','B.03','Ritik','5.56','B','7.06','ACA',\n",
    "        'Brithika','CGPA','24','Pihu','BB','Jhanvi','Entrepreneur','8.56',\n",
    "        'LHM','Lata','S.Arch','Marsh','HCA','5.88','B.Student','LL B.Ed',\n",
    "        'M.S','Navya','Mahika','Mthanya','Working Professional','Esha',\n",
    "        'LLS','LLEd','E.Tech','Doctor','N.Pharm','LCA','Mihir','Advait'\n",
    "    ]\n",
    "\n",
    "df_train['Degree'] = df_train['Degree'].apply(\n",
    "        lambda x: \"Unknown\" if x in invalid_degrees else x\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3620f867",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_degrees_extra = [\n",
    "    'UX/UI Designer', 'BH', 'S.Tech', 'Kalyan', \n",
    "    'LLTech', 'Aarav', 'B.3.79', 'LL.Com', 'K.Ed'\n",
    "]\n",
    "\n",
    "df_train['Degree'] = df_train['Degree'].apply(\n",
    "    lambda x: \"Unknown\" if x in invalid_degrees_extra else x\n",
    ")\n",
    "\n",
    "df_train['Degree'] = df_train['Degree'].replace({\n",
    "    'LL.B': 'LLB'\n",
    "})\n",
    "\n",
    "df_train['Degree'] = df_train['Degree'].str.replace('.', '', regex=False).str.strip().str.upper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99272ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name ['Aaradhya' 'Vivan' 'Yuvraj' 'Rhea' 'Vani' 'Ritvik' 'Rajveer' 'Aishwarya'\n",
      " 'Simran' 'Utkarsh' 'Aahana' 'Tejas' 'Aadhya' 'Kiran' 'Aditi' 'Suhani'\n",
      " 'Jiya' 'Bhavesh' 'Armaan' 'Ishaani' 'Prachi' 'Pratyush' 'Abhinav'\n",
      " 'Siddhesh' 'Aditya' 'Aarav' 'Asha' 'Kashish' 'Prisha' 'Chhavi' 'Tanmay'\n",
      " 'Vihaan' 'Shiv' 'Anvi' 'Darsh' 'Samar' 'Raunak' 'Mahi' 'Shaurya' 'Vidya'\n",
      " 'Jai' 'Ayush' 'Ansh' 'Anand' 'Yashvi' 'Shrey' 'Ritika' 'Mihir' 'Isha'\n",
      " 'Arjun' 'Rohan' 'Pratham' 'Nirvaan' 'Ishaan' 'Aarya' 'Riya' 'Aariv'\n",
      " 'Raghavendra' 'Mahika' 'Abhishek' 'Harshil' 'Janvi' 'Kartikeya' 'Shivam'\n",
      " 'Advait' 'Reyansh' 'Saanvi' 'Ivaan' 'Pallavi' 'Sneha' 'Ayaan' 'Aakash'\n",
      " 'Raghav' 'Satyam' 'Aarush' 'Vibha' 'Rupal' 'Sanya' 'Mira' 'Rashi' 'Shlok'\n",
      " 'Harsha' 'Divya' 'Pranav' 'Hrithik' 'Tushar' 'Garima' 'Zoya' 'Kian'\n",
      " 'Navya' 'Lakshay' 'Kriti' 'Palak' 'Aryan' 'Parth' 'Ishan' 'Rupak'\n",
      " 'Atharv' 'Aarti' 'Anirudh' 'Kabir' 'Sanjeev' 'Sanket' 'Tara' 'Gagan'\n",
      " 'Anjali' 'Gaurav' 'Vikram' 'Yogesh' 'Ila' 'Rishi' 'Ayansh' 'Kolkata'\n",
      " 'Kavya' 'Aanchal' 'Vedant' 'Samaira' 'Harsh' 'Nikita' 'Charvi' 'Ishita'\n",
      " 'Ishwar' 'Kanika' 'Ritik' 'Rahil' 'Ira' 'Pari' 'Tanya' 'Yamini' 'Vidhi'\n",
      " 'Shreya' 'Neha' 'Esha' 'Damini' 'Manvi' 'Shivansh' 'Nikhil' 'Arya'\n",
      " 'Deepak' 'Shruti' 'Vrinda' 'Anushka' 'Sara' 'Zara' 'Gauri' 'Soham'\n",
      " 'Nandini' 'Siddharth' 'Rudransh' 'Manan' 'Dhruv' 'Tina' 'Pihu' 'Lavanya'\n",
      " 'Anika' 'Sai' 'Tanisha' 'Amit' 'Arav' 'Chirag' 'Krishna' 'Pooja' 'Eshita'\n",
      " 'Leela' 'Siddhi' 'Vanya' 'Trisha' 'Vivaan' 'Diya' 'Veda' 'Keshav' 'Kunal'\n",
      " 'Arnav' 'Barkha' 'Nalini' 'Golkut' 'Jasmine' 'Mithila' 'Rupa' 'Nisha'\n",
      " 'Saurav' 'Radhika' 'Jhanvi' 'Monika' 'Varun' 'Aan' 'Dev' 'Rajat' 'Naina'\n",
      " 'Nishant' 'Yash' 'Vaishnavi' 'Himani' 'Meera' 'Om' 'Anaya' 'Aniket'\n",
      " 'Tanvi' 'Mayank' 'Ishaesh' 'Srishti' 'Lata' 'Mukund' 'Ranveer' 'Khushi'\n",
      " 'Aarohi' 'Bhavna' 'Neil' 'Shivak' 'Apoorva' 'Kartik' 'Avni' 'Vaanya'\n",
      " 'Kush' 'Karishma' 'Shanaya' 'Virat' 'Rudra' 'A.Ed' 'Kiara' 'Krav' 'Ayhan'\n",
      " 'Nakul' 'Kalyan' 'Parvik' 'Vlaan' 'Harini' 'Mahak' 'Shivar' 'Abishma'\n",
      " 'Prvi' 'K. Kavya' 'Aieter' 'Aarsh' 'Aarvi' 'Kupa' 'Rudegrav' 'Parvi'\n",
      " 'Siddh' 'Rajankot' 'Ani' 'Rupil' 'Aarash' 'Taurav' 'Rani' 'Aanya' 'BE'\n",
      " 'Aavya' 'Raghavvi' 'Anarush' 'Aisha' 'Viv' 'Ronnie' '18' 'Rietal' 'R.Com'\n",
      " 'Anohi' 'Vivani' 'Ayash' 'Anil' 'Tarsh' 'Aiya' 'Patna' 'Tinmay' 'Rhesh'\n",
      " 'Shivna' 'Nikya' 'Arnar' 'Vakash' 'Jush' 'Randik' 'Siddir' 'Adachi'\n",
      " 'Anakash' 'Ayut' 'Pariv' 'Jhaan' 'Rai' 'Hreya' 'Shivivaam' 'Prishti'\n",
      " 'M.Com' 'Gavrachi' 'Rivaan' 'Haurav' 'Noreen' 'Anish' 'Shivan' 'Aniv'\n",
      " 'Aohi' 'Vashi' 'Aariket' 'Aarat' 'Vohi' 'Vavya' 'Hra' 'Ishaam' 'Anhil'\n",
      " 'Rieta' 'Zahra' 'Jathesh' 'Jhav' 'Anh' 'Vidvi' 'Raghavik' 'Mahir' 'Sansh'\n",
      " 'Shivvi' 'Prishant' 'Rupar' 'Eirini' 'Tanak' 'Researcher' 'Shaina' 'Aani'\n",
      " 'Plumber' 'Nanya' 'Manik' 'Nanchal' 'Ayoub' 'Aam' 'Airav' 'Zegmay'\n",
      " 'Aarsush' 'Vidra' 'Kani' 'Ishma' 'Naly' 'Jaish' 'Rajya' 'Chrinda' 'Tani'\n",
      " 'Harshand' 'Ranchal' 'Vita' 'Prandini' 'Mahav' 'Nhanini' 'Anupal' 'Manr'\n",
      " 'Eikram' 'Arsha' 'Kartika' 'Pradhya' 'Harshir' 'Shivlok' 'Shivwar'\n",
      " 'Abarav' 'Ayya' 'Rupai' 'Rudrithik' 'Varanasi' 'K.Pharm' 'UX/UI Designer'\n",
      " 'Ariti' 'Manjun' 'Arvik' 'Thane' 'Rupika' 'Aaransh' 'Ijra' 'Anar' 'Parha'\n",
      " 'Vidha' 'Prayat' 'Yurav' 'Srinagar' 'Aaranya' 'Rupadhya' 'Anishi'\n",
      " 'Aikash' 'Nhanvi' 'Jiram' 'Rudrey' 'Shashi' 'Anya' 'Eisha' 'Vhaani'\n",
      " 'Prilak' 'Aarani' 'Nya' 'Harshav' 'Ewesh' 'Aanket' 'Tohar' 'Ryouvik'\n",
      " 'Niya' 'Anjun' 'Rupat' 'Anahk' 'Shivsh' 'Niki' 'Nishita' 'Rohik' 'Prishi'\n",
      " 'Ishaansh' 'Virar' 'Sharth' 'M.Tech' 'Shir' 'Kike' 'Shivvaan' 'Aarla'\n",
      " 'Nishi' 'Aarand' 'Adiya' 'Ritak' 'Kashi' 'Krey' 'Prarav' 'Kartal'\n",
      " 'Anariv' 'Irit' 'Kanisha' 'Anisha' 'Harshaun' 'Rietvik' 'Vasai-Virar'\n",
      " 'Ishlok' 'Vika' 'Rika' 'Aarun']\n",
      "Gender ['Female' 'Male']\n",
      "City ['Ludhiana' 'Varanasi' 'Visakhapatnam' 'Mumbai' 'Kanpur' 'Ahmedabad'\n",
      " 'Thane' 'Nashik' 'Bangalore' 'Patna' 'Rajkot' 'Jaipur' 'Pune' 'Lucknow'\n",
      " 'Meerut' 'Agra' 'Surat' 'Faridabad' 'Hyderabad' 'Srinagar' 'Ghaziabad'\n",
      " 'Kolkata' 'Chennai' 'Kalyan' 'Nagpur' 'Vadodara' 'Vasai-Virar' 'Delhi'\n",
      " 'Bhopal' 'Indore' 'Unknown' 'Gurgaon' 'Morena']\n",
      "Working Professional or Student ['Working Professional' 'Student']\n",
      "Profession ['Chef' 'Teacher' nan 'Business Analyst' 'Financial Analyst' 'Chemist'\n",
      " 'Electrician' 'Software Engineer' 'Data Scientist' 'Plumber'\n",
      " 'Marketing Manager' 'Accountant' 'Entrepreneur' 'HR Manager'\n",
      " 'UX/UI Designer' 'Content Writer' 'Educational Consultant'\n",
      " 'Civil Engineer' 'Manager' 'Pharmacist' 'Architect' 'Mechanical Engineer'\n",
      " 'Customer Support' 'Consultant' 'Judge' 'Researcher' 'Pilot'\n",
      " 'Graphic Designer' 'Travel Consultant' 'Digital Marketer' 'Lawyer'\n",
      " 'Research Analyst' 'Sales Executive' 'Doctor' 'Unemployed'\n",
      " 'Investment Banker' 'Family Consultant' 'Unknown' 'Analyst']\n",
      "Sleep Duration ['8-9 hours' '<5 hours' '5-6 hours' '7-8 hours' 'Unknown' '6-8 hours'\n",
      " '6-7 hours' '9-11 hours']\n",
      "Dietary Habits ['Healthy' 'Unhealthy' 'Moderate' 'Unknown' nan]\n",
      "Degree ['BHM' 'LLB' 'BPHARM' 'BBA' 'MCA' 'MD' 'BSC' 'ME' 'BARCH' 'BCA' 'BE' 'MA'\n",
      " 'BED' 'BCOM' 'MBA' 'MCOM' 'MHM' 'BA' 'CLASS 12' 'MTECH' 'PHD' 'MED' 'MSC'\n",
      " 'BTECH' 'LLM' 'MBBS' 'MPHARM' 'UNKNOWN' 'MPA' 'CLASS 11' 'MARCH' 'LED'\n",
      " 'PPHARM' 'BBARCH' nan 'RCA']\n",
      "Have you ever had suicidal thoughts ? ['No' 'Yes']\n",
      "Family History of Mental Illness ['No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "for i in df_train.select_dtypes(include = [\"object\"]).columns:\n",
    "\t\t\t print(i, df_train[i].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b45a7d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                            0\n",
       "Name                                          0\n",
       "Gender                                        0\n",
       "Age                                           0\n",
       "City                                          0\n",
       "Working Professional or Student               0\n",
       "Profession                                36630\n",
       "Academic Pressure                        112803\n",
       "Work Pressure                             27918\n",
       "CGPA                                     112802\n",
       "Study Satisfaction                       112803\n",
       "Job Satisfaction                          27910\n",
       "Sleep Duration                                0\n",
       "Dietary Habits                                0\n",
       "Degree                                        2\n",
       "Have you ever had suicidal thoughts ?         0\n",
       "Work/Study Hours                              0\n",
       "Financial Stress                              4\n",
       "Family History of Mental Illness              0\n",
       "Depression                                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4cdbe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=['Name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "490167a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140700, 19)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f631f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of working professionals with NaN in Profession: 8763\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nan_prof_working_professionals = df_train[(df_train['Working Professional or Student'] == 'Working Professional') & (df_train['Profession'].isna())]\n",
    "\n",
    "\n",
    "count_nan_prof_working = nan_prof_working_professionals.shape[0]\n",
    "\n",
    "print(f\"Number of working professionals with NaN in Profession: {count_nan_prof_working}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9514bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_student = (df_train['Working Professional or Student'] == 'Student') & (df_train['Profession'].isna())\n",
    "df_train.loc[mask_student, 'Profession'] = 'Student'\n",
    "\n",
    "\n",
    "mask_working = (df_train['Working Professional or Student'] == 'Working Professional') & (df_train['Profession'].isna())\n",
    "df_train.loc[mask_working, 'Profession'] = 'Unknown'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f50d09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Professional or Student\n",
      "Student                      9\n",
      "Working Professional    112794\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nan_academic_pressure_counts = df_train[df_train['Academic Pressure'].isna()].groupby('Working Professional or Student').size()\n",
    "\n",
    "print(nan_academic_pressure_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c716cc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_student_pressure = df_train.loc[df_train['Working Professional or Student'] == 'Student', 'Academic Pressure'].median()\n",
    "\n",
    "mask_student_nan = (df_train['Working Professional or Student'] == 'Student') & (df_train['Academic Pressure'].isna())\n",
    "df_train.loc[mask_student_nan, 'Academic Pressure'] = median_student_pressure\n",
    "\n",
    "\n",
    "mask_working_nan = (df_train['Working Professional or Student'] == 'Working Professional') & (df_train['Academic Pressure'].isna())\n",
    "df_train.loc[mask_working_nan, 'Academic Pressure'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0f1757f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of working professionals with NaN in Work Pressure: 20\n"
     ]
    }
   ],
   "source": [
    "nan_work_pressure_working = df_train[(df_train['Work Pressure'].isna()) & (df_train['Working Professional or Student'] == 'Working Professional')]\n",
    "\n",
    "count_nan_work_pressure_working = nan_work_pressure_working.shape[0]\n",
    "\n",
    "print(f\"Number of working professionals with NaN in Work Pressure: {count_nan_work_pressure_working}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4293dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_work_pressure = df_train.loc[df_train['Working Professional or Student'] == 'Working Professional', 'Work Pressure'].median()\n",
    "\n",
    "mask_nan_working = (df_train['Working Professional or Student'] == 'Working Professional') & (df_train['Work Pressure'].isna())\n",
    "df_train.loc[mask_nan_working, 'Work Pressure'] = median_work_pressure\n",
    "\n",
    "mask_nan_students = (df_train['Working Professional or Student'] == 'Student') & (df_train['Work Pressure'].isna())\n",
    "df_train.loc[mask_nan_students, 'Work Pressure'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bd516f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Professional or Student\n",
      "Student                      9\n",
      "Working Professional    112793\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_cgpa_counts = df_train[df_train['CGPA'].isna()].groupby('Working Professional or Student').size()\n",
    "\n",
    "print(nan_cgpa_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd748931",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_cgpa_students = df_train.loc[df_train['Working Professional or Student'] == 'Student', 'CGPA'].median()\n",
    "\n",
    "mask_student_cgpa_nan = (df_train['Working Professional or Student'] == 'Student') & (df_train['CGPA'].isna())\n",
    "df_train.loc[mask_student_cgpa_nan, 'CGPA'] = median_cgpa_students\n",
    "\n",
    "mask_working_cgpa_nan = (df_train['Working Professional or Student'] == 'Working Professional') & (df_train['CGPA'].isna())\n",
    "df_train.loc[mask_working_cgpa_nan, 'CGPA'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb68617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Professional or Student\n",
      "Student                     10\n",
      "Working Professional    112793\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_study_satisfaction_counts = df_train[df_train['Study Satisfaction'].isna()].groupby('Working Professional or Student').size()\n",
    "\n",
    "print(nan_study_satisfaction_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a6a1f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_study_satisfaction_students = df_train.loc[df_train['Working Professional or Student'] == 'Student', 'Study Satisfaction'].median()\n",
    "\n",
    "mask_student_study_nan = (df_train['Working Professional or Student'] == 'Student') & (df_train['Study Satisfaction'].isna())\n",
    "df_train.loc[mask_student_study_nan, 'Study Satisfaction'] = median_study_satisfaction_students\n",
    "\n",
    "mask_working_study_nan = (df_train['Working Professional or Student'] == 'Working Professional') & (df_train['Study Satisfaction'].isna())\n",
    "df_train.loc[mask_working_study_nan, 'Study Satisfaction'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60ddd71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Professional or Student\n",
      "Student                 27893\n",
      "Working Professional       17\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_job_satisfaction_counts = df_train[df_train['Job Satisfaction'].isna()].groupby('Working Professional or Student').size()\n",
    "\n",
    "print(nan_job_satisfaction_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ccebbfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_job_satisfaction_working = df_train.loc[df_train['Working Professional or Student'] == 'Working Professional', 'Job Satisfaction'].median()\n",
    "\n",
    "mask_working_job_nan = (df_train['Working Professional or Student'] == 'Working Professional') & (df_train['Job Satisfaction'].isna())\n",
    "df_train.loc[mask_working_job_nan, 'Job Satisfaction'] = median_job_satisfaction_working\n",
    "\n",
    "mask_student_job_nan = (df_train['Working Professional or Student'] == 'Student') & (df_train['Job Satisfaction'].isna())\n",
    "df_train.loc[mask_student_job_nan, 'Job Satisfaction'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87c5d5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                       0\n",
       "Gender                                   0\n",
       "Age                                      0\n",
       "City                                     0\n",
       "Working Professional or Student          0\n",
       "Profession                               0\n",
       "Academic Pressure                        0\n",
       "Work Pressure                            0\n",
       "CGPA                                     0\n",
       "Study Satisfaction                       0\n",
       "Job Satisfaction                         0\n",
       "Sleep Duration                           0\n",
       "Dietary Habits                           4\n",
       "Degree                                   2\n",
       "Have you ever had suicidal thoughts ?    0\n",
       "Work/Study Hours                         0\n",
       "Financial Stress                         4\n",
       "Family History of Mental Illness         0\n",
       "Depression                               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54688a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prakash Kumar\\AppData\\Local\\Temp\\ipykernel_2228\\118052492.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_train['Dietary Habits'].fillna(df_train['Dietary Habits'].mode()[0], inplace=True)\n",
      "C:\\Users\\Prakash Kumar\\AppData\\Local\\Temp\\ipykernel_2228\\118052492.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_train['Degree'].fillna(df_train['Degree'].mode(), inplace=True)\n",
      "C:\\Users\\Prakash Kumar\\AppData\\Local\\Temp\\ipykernel_2228\\118052492.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_train['Financial Stress'].fillna(df_train['Financial Stress'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_train['Dietary Habits'].fillna(df_train['Dietary Habits'].mode()[0], inplace=True)\n",
    "df_train['Degree'].fillna(df_train['Degree'].mode(), inplace=True)\n",
    "\n",
    "\n",
    "df_train['Financial Stress'].fillna(df_train['Financial Stress'].median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50799920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                       0\n",
       "Gender                                   0\n",
       "Age                                      0\n",
       "City                                     0\n",
       "Working Professional or Student          0\n",
       "Profession                               0\n",
       "Academic Pressure                        0\n",
       "Work Pressure                            0\n",
       "CGPA                                     0\n",
       "Study Satisfaction                       0\n",
       "Job Satisfaction                         0\n",
       "Sleep Duration                           0\n",
       "Dietary Habits                           0\n",
       "Degree                                   2\n",
       "Have you ever had suicidal thoughts ?    0\n",
       "Work/Study Hours                         0\n",
       "Financial Stress                         0\n",
       "Family History of Mental Illness         0\n",
       "Depression                               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ef4ef4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_degree = df_train['Degree'].mode()[0]\n",
    "df_train['Degree'].fillna(mode_degree, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb96da72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                       0\n",
       "Gender                                   0\n",
       "Age                                      0\n",
       "City                                     0\n",
       "Working Professional or Student          0\n",
       "Profession                               0\n",
       "Academic Pressure                        0\n",
       "Work Pressure                            0\n",
       "CGPA                                     0\n",
       "Study Satisfaction                       0\n",
       "Job Satisfaction                         0\n",
       "Sleep Duration                           0\n",
       "Dietary Habits                           0\n",
       "Degree                                   0\n",
       "Have you ever had suicidal thoughts ?    0\n",
       "Work/Study Hours                         0\n",
       "Financial Stress                         0\n",
       "Family History of Mental Illness         0\n",
       "Depression                               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae3724c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140700, 19)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54d64b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = df_train['id'].copy()\n",
    "\n",
    "\n",
    "df_train = df_train.drop(columns=['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e5662e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140700, 18)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426239b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train.to_csv('after_imputation_new.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89bb23f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\n",
    "    'Gender', \n",
    "    'City', \n",
    "    'Working Professional or Student', \n",
    "    'Profession', \n",
    "    'Dietary Habits', \n",
    "    'Degree', \n",
    "    'Have you ever had suicidal thoughts ?',\n",
    "    'Family History of Mental Illness',\n",
    "    'Sleep Duration'\n",
    "]\n",
    "\n",
    "df_train_encoded = pd.get_dummies(df_train, columns=categorical_cols, drop_first=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "034143ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 140700 entries, 0 to 140699\n",
      "Columns: 136 entries, Age to Sleep Duration_Unknown\n",
      "dtypes: bool(127), float64(8), int64(1)\n",
      "memory usage: 26.7 MB\n"
     ]
    }
   ],
   "source": [
    "df_train_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a8d55002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(5)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_encoded.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5cb5988e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140700, 136)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30210ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Age  Academic Pressure  Work Pressure  CGPA  Study Satisfaction  \\\n",
      "492     18.0                0.0            5.0   0.0                 0.0   \n",
      "19327   19.0                0.0            3.0   0.0                 0.0   \n",
      "30355   18.0                0.0            5.0   0.0                 0.0   \n",
      "37622   38.0                0.0            2.0   0.0                 0.0   \n",
      "60522   18.0                0.0            5.0   0.0                 0.0   \n",
      "94630   18.0                0.0            5.0   0.0                 0.0   \n",
      "99689   38.0                0.0            2.0   0.0                 0.0   \n",
      "105130  19.0                0.0            3.0   0.0                 0.0   \n",
      "115007  18.0                0.0            5.0   0.0                 0.0   \n",
      "121194  18.0                0.0            5.0   0.0                 0.0   \n",
      "\n",
      "        Job Satisfaction  Work/Study Hours  Financial Stress  Depression  \\\n",
      "492                  1.0              11.0               5.0           1   \n",
      "19327                2.0              12.0               5.0           1   \n",
      "30355                1.0              11.0               5.0           1   \n",
      "37622                2.0               5.0               3.0           0   \n",
      "60522                2.0              12.0               5.0           1   \n",
      "94630                1.0              11.0               5.0           1   \n",
      "99689                2.0               5.0               3.0           0   \n",
      "105130               2.0              12.0               5.0           1   \n",
      "115007               1.0              11.0               5.0           1   \n",
      "121194               2.0              12.0               5.0           1   \n",
      "\n",
      "        Gender_Female  ...  Family History of Mental Illness_No  \\\n",
      "492              True  ...                                False   \n",
      "19327           False  ...                                 True   \n",
      "30355           False  ...                                 True   \n",
      "37622           False  ...                                 True   \n",
      "60522           False  ...                                False   \n",
      "94630           False  ...                                 True   \n",
      "99689           False  ...                                 True   \n",
      "105130          False  ...                                 True   \n",
      "115007           True  ...                                False   \n",
      "121194          False  ...                                False   \n",
      "\n",
      "        Family History of Mental Illness_Yes  Sleep Duration_5-6 hours  \\\n",
      "492                                     True                     False   \n",
      "19327                                  False                     False   \n",
      "30355                                  False                     False   \n",
      "37622                                  False                     False   \n",
      "60522                                   True                     False   \n",
      "94630                                  False                     False   \n",
      "99689                                  False                     False   \n",
      "105130                                 False                     False   \n",
      "115007                                  True                     False   \n",
      "121194                                  True                     False   \n",
      "\n",
      "        Sleep Duration_6-7 hours  Sleep Duration_6-8 hours  \\\n",
      "492                        False                     False   \n",
      "19327                      False                     False   \n",
      "30355                      False                     False   \n",
      "37622                      False                     False   \n",
      "60522                      False                     False   \n",
      "94630                      False                     False   \n",
      "99689                      False                     False   \n",
      "105130                     False                     False   \n",
      "115007                     False                     False   \n",
      "121194                     False                     False   \n",
      "\n",
      "        Sleep Duration_7-8 hours  Sleep Duration_8-9 hours  \\\n",
      "492                        False                     False   \n",
      "19327                       True                     False   \n",
      "30355                       True                     False   \n",
      "37622                       True                     False   \n",
      "60522                      False                     False   \n",
      "94630                       True                     False   \n",
      "99689                       True                     False   \n",
      "105130                      True                     False   \n",
      "115007                     False                     False   \n",
      "121194                     False                     False   \n",
      "\n",
      "        Sleep Duration_9-11 hours  Sleep Duration_<5 hours  \\\n",
      "492                         False                     True   \n",
      "19327                       False                    False   \n",
      "30355                       False                    False   \n",
      "37622                       False                    False   \n",
      "60522                       False                     True   \n",
      "94630                       False                    False   \n",
      "99689                       False                    False   \n",
      "105130                      False                    False   \n",
      "115007                      False                     True   \n",
      "121194                      False                     True   \n",
      "\n",
      "        Sleep Duration_Unknown  \n",
      "492                      False  \n",
      "19327                    False  \n",
      "30355                    False  \n",
      "37622                    False  \n",
      "60522                    False  \n",
      "94630                    False  \n",
      "99689                    False  \n",
      "105130                   False  \n",
      "115007                   False  \n",
      "121194                   False  \n",
      "\n",
      "[10 rows x 136 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "duplicate_rows = df_train_encoded[df_train_encoded.duplicated(keep=False)]\n",
    "\n",
    "print(duplicate_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7ae2adfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_encoded = df_train_encoded.drop_duplicates(keep='first').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b4cced7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_encoded.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2ae79a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train_encoded.to_csv('encoded_new.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fd907bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = [\n",
    "    'Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction',\n",
    "    'Job Satisfaction', 'Work/Study Hours', 'Financial Stress'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "872812c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers in Age: 0\n",
      "Outliers in Academic Pressure: 6296\n",
      "Outliers in Work Pressure: 0\n",
      "Outliers in CGPA: 0\n",
      "Outliers in Study Satisfaction: 4423\n",
      "Outliers in Job Satisfaction: 0\n",
      "Outliers in Work/Study Hours: 0\n",
      "Outliers in Financial Stress: 0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "outliers = {}\n",
    "for col in numerical_cols:\n",
    "    z_scores = zscore(df_train_encoded[col])\n",
    "    outliers[col] = (abs(z_scores) > 3).sum()\n",
    "    print(f'Outliers in {col}: {outliers[col]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6d91e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Skewness  Kurtosis\n",
      "Age                -0.217996 -1.149276\n",
      "Academic Pressure   2.119564  3.091727\n",
      "Work Pressure       0.053482 -1.291064\n",
      "CGPA                1.670775  1.024931\n",
      "Study Satisfaction  2.190913  3.490002\n",
      "Job Satisfaction    0.084654 -1.280437\n",
      "Work/Study Hours   -0.128141 -1.283422\n",
      "Financial Stress    0.035645 -1.313591\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "numerical_cols = [\n",
    "    'Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction',\n",
    "    'Job Satisfaction', 'Work/Study Hours', 'Financial Stress'\n",
    "]\n",
    "\n",
    "\n",
    "skewness_values = df_train_encoded[numerical_cols].apply(lambda x: skew(x, bias=False))\n",
    "\n",
    "\n",
    "kurtosis_values = df_train_encoded[numerical_cols].apply(lambda x: kurtosis(x, fisher=True, bias=False))\n",
    "\n",
    "stats_df = pd.DataFrame({\n",
    "    'Skewness': skewness_values,\n",
    "    'Kurtosis': kurtosis_values\n",
    "})\n",
    "\n",
    "print(stats_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c013f651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "cols_to_transform = ['Academic Pressure', 'CGPA', 'Study Satisfaction']\n",
    "\n",
    "for col in cols_to_transform:\n",
    "    df_train_encoded[col] = np.log1p(df_train_encoded[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "72efe3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers in Age: 0\n",
      "Outliers in Academic Pressure: 0\n",
      "Outliers in Work Pressure: 0\n",
      "Outliers in CGPA: 0\n",
      "Outliers in Study Satisfaction: 0\n",
      "Outliers in Job Satisfaction: 0\n",
      "Outliers in Work/Study Hours: 0\n",
      "Outliers in Financial Stress: 0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "outliers = {}\n",
    "for col in numerical_cols:\n",
    "    z_scores = zscore(df_train_encoded[col])\n",
    "    outliers[col] = (abs(z_scores) > 3).sum()\n",
    "    print(f'Outliers in {col}: {outliers[col]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb78aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Skewness  Kurtosis\n",
      "Age                -0.217996 -1.149276\n",
      "Academic Pressure   1.786881  1.487176\n",
      "Work Pressure       0.053482 -1.291064\n",
      "CGPA                1.542897  0.428197\n",
      "Study Satisfaction  1.818102  1.647927\n",
      "Job Satisfaction    0.084654 -1.280437\n",
      "Work/Study Hours   -0.128141 -1.283422\n",
      "Financial Stress    0.035645 -1.313591\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "numerical_cols = [\n",
    "    'Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction',\n",
    "    'Job Satisfaction', 'Work/Study Hours', 'Financial Stress'\n",
    "]\n",
    "\n",
    "skewness_values = df_train_encoded[numerical_cols].apply(lambda x: skew(x, bias=False))\n",
    "\n",
    "kurtosis_values = df_train_encoded[numerical_cols].apply(lambda x: kurtosis(x, fisher=True, bias=False))\n",
    "\n",
    "stats_df = pd.DataFrame({\n",
    "    'Skewness': skewness_values,\n",
    "    'Kurtosis': kurtosis_values\n",
    "})\n",
    "\n",
    "print(stats_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4e995eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train_encoded.to_csv('final_new.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d4444141",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_final = pd.read_csv(r\"D:\\GUVI\\Mental_health_survey\\env\\final_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3cfd0f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers in Age: 0\n",
      "Outliers in Academic Pressure: 0\n",
      "Outliers in Work Pressure: 0\n",
      "Outliers in CGPA: 0\n",
      "Outliers in Study Satisfaction: 0\n",
      "Outliers in Job Satisfaction: 0\n",
      "Outliers in Work/Study Hours: 0\n",
      "Outliers in Financial Stress: 0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "outliers = {}\n",
    "for col in numerical_cols:\n",
    "    z_scores = zscore(df_train_final[col])\n",
    "    outliers[col] = (abs(z_scores) > 3).sum()\n",
    "    print(f'Outliers in {col}: {outliers[col]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863a901c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Skewness  Kurtosis\n",
      "Age                -0.217996 -1.149276\n",
      "Academic Pressure   1.786881  1.487176\n",
      "Work Pressure       0.053482 -1.291064\n",
      "CGPA                1.542897  0.428197\n",
      "Study Satisfaction  1.818102  1.647927\n",
      "Job Satisfaction    0.084654 -1.280437\n",
      "Work/Study Hours   -0.128141 -1.283422\n",
      "Financial Stress    0.035645 -1.313591\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "numerical_cols = [\n",
    "    'Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction',\n",
    "    'Job Satisfaction', 'Work/Study Hours', 'Financial Stress'\n",
    "]\n",
    "\n",
    "skewness_values = df_train_final[numerical_cols].apply(lambda x: skew(x, bias=False))\n",
    "\n",
    "kurtosis_values = df_train_final[numerical_cols].apply(lambda x: kurtosis(x, fisher=True, bias=False))\n",
    "\n",
    "stats_df = pd.DataFrame({\n",
    "    'Skewness': skewness_values,\n",
    "    'Kurtosis': kurtosis_values\n",
    "})\n",
    "\n",
    "print(stats_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a3c8c91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "bins = [0, 18, 30, 45, 60, 100]\n",
    "labels = ['<18', '18-29', '30-44', '45-59', '60+']\n",
    "df_train_final['age_group'] = pd.cut(df_train_final['Age'], bins=bins, labels=labels, right=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ab7502",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train_final.drop(columns=['Depression'])\n",
    "y = df_train_final['Depression']\n",
    "\n",
    "profession_cols = [col for col in X.columns if col.startswith(\"Working Professional or Student\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc41d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroup 45-59-Student: {0: 9, 1: 2} → After SMOTE: {0: 9, 1: 9}\n",
      "Subgroup 45-59-Working Professional: {0: 57680, 1: 526} → After SMOTE: {0: 57680, 1: 57680}\n",
      "Subgroup 18-29-Student: {1: 13368, 0: 7289} → After SMOTE: {0: 13368, 1: 13368}\n",
      "Subgroup 18-29-Working Professional: {0: 7873, 1: 6686} → After SMOTE: {1: 7873, 0: 7873}\n",
      "Subgroup 30-44-Student: {0: 4267, 1: 2966} → After SMOTE: {1: 4267, 0: 4267}\n",
      "Subgroup 30-44-Working Professional: {0: 35523, 1: 2005} → After SMOTE: {0: 35523, 1: 35523}\n",
      "Skipping subgroup 60+ - Working Professional or Student_Student (no samples)\n",
      "Subgroup 60+-Working Professional: {0: 2491, 1: 10} → After SMOTE: {0: 2491, 1: 2491}\n"
     ]
    }
   ],
   "source": [
    "X_resampled_list = []\n",
    "y_resampled_list = []\n",
    "\n",
    "\n",
    "for age_group in df_train_final['age_group'].unique():\n",
    "    for prof_col in profession_cols:\n",
    "        \n",
    "        mask = (df_train_final['age_group'] == age_group) & (X[prof_col] == 1)\n",
    "        X_group = X[mask].drop(columns=['age_group'])\n",
    "        y_group = y[mask]\n",
    "\n",
    "        if len(X_group) == 0:\n",
    "            print(f\"Skipping subgroup {age_group} - {prof_col} (no samples)\")\n",
    "            continue\n",
    "\n",
    "        \n",
    "        minority_count = y_group.value_counts().min()\n",
    "\n",
    "        if minority_count < 2:\n",
    "            print(f\"Skipping SMOTE for subgroup {age_group} - {prof_col} (too few minority samples)\")\n",
    "            X_resampled_list.append(X_group)\n",
    "            y_resampled_list.append(y_group)\n",
    "            continue\n",
    "\n",
    "        \n",
    "        k_neighbors = min(5, minority_count - 1)\n",
    "\n",
    "        sm = SMOTE(random_state=42, k_neighbors=k_neighbors)\n",
    "        X_res, y_res = sm.fit_resample(X_group, y_group)\n",
    "\n",
    "        print(f\"Subgroup {age_group}-{prof_col.split('_')[-1]}: \"\n",
    "              f\"{y_group.value_counts().to_dict()} → After SMOTE: {y_res.value_counts().to_dict()}\")\n",
    "\n",
    "        X_resampled_list.append(X_res)\n",
    "        y_resampled_list.append(y_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b4980f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final shape after Age × Profession SMOTE: (242422, 135) (242422,)\n"
     ]
    }
   ],
   "source": [
    "X_balanced = pd.concat(X_resampled_list, axis=0) \n",
    "y_balanced = pd.concat(y_resampled_list, axis=0)\n",
    "print(\"✅ Final shape after Age × Profession SMOTE:\", X_balanced.shape, y_balanced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "647f2444",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "01077dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature_cols.save']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(feature_cols, \"feature_cols.save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c61460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (169695, 135) (169695,)\n",
      "Val shape: (23999, 135) (23999,)\n",
      "Test shape: (48728, 135) (48728,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_balanced, y_balanced,\n",
    "    test_size=0.3, stratify=y_balanced, random_state=42\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.67, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Val shape:\", X_val.shape, y_val.shape)\n",
    "print(\"Test shape:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e57e999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled   = scaler.transform(X_val)\n",
    "X_test_scaled  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daecadf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GUVI\\Mental_health_survey\\env\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train_scaled.shape[1], activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(1, activation=\"sigmoid\")) \n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\", Precision(name='precision'), Recall(name='recall'), AUC(name='auc')]\n",
    ")\n",
    "\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fe86160e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - accuracy: 0.9231 - auc: 0.9785 - loss: 0.1885 - precision: 0.9289 - recall: 0.9162 - val_accuracy: 0.9585 - val_auc: 0.9928 - val_loss: 0.1056 - val_precision: 0.9594 - val_recall: 0.9574\n",
      "Epoch 2/50\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9532 - auc: 0.9907 - loss: 0.1201 - precision: 0.9574 - recall: 0.9487 - val_accuracy: 0.9615 - val_auc: 0.9937 - val_loss: 0.0980 - val_precision: 0.9739 - val_recall: 0.9484\n",
      "Epoch 3/50\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9562 - auc: 0.9919 - loss: 0.1116 - precision: 0.9608 - recall: 0.9511 - val_accuracy: 0.9612 - val_auc: 0.9938 - val_loss: 0.0970 - val_precision: 0.9768 - val_recall: 0.9449\n",
      "Epoch 4/50\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9574 - auc: 0.9925 - loss: 0.1077 - precision: 0.9618 - recall: 0.9525 - val_accuracy: 0.9623 - val_auc: 0.9940 - val_loss: 0.0944 - val_precision: 0.9693 - val_recall: 0.9548\n",
      "Epoch 5/50\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9588 - auc: 0.9929 - loss: 0.1042 - precision: 0.9628 - recall: 0.9544 - val_accuracy: 0.9626 - val_auc: 0.9940 - val_loss: 0.0942 - val_precision: 0.9709 - val_recall: 0.9537\n",
      "Epoch 6/50\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9592 - auc: 0.9932 - loss: 0.1024 - precision: 0.9626 - recall: 0.9557 - val_accuracy: 0.9632 - val_auc: 0.9941 - val_loss: 0.0931 - val_precision: 0.9689 - val_recall: 0.9571\n",
      "Epoch 7/50\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9602 - auc: 0.9934 - loss: 0.1008 - precision: 0.9644 - recall: 0.9556 - val_accuracy: 0.9638 - val_auc: 0.9943 - val_loss: 0.0917 - val_precision: 0.9707 - val_recall: 0.9565\n",
      "Epoch 8/50\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9603 - auc: 0.9936 - loss: 0.0990 - precision: 0.9639 - recall: 0.9564 - val_accuracy: 0.9638 - val_auc: 0.9943 - val_loss: 0.0923 - val_precision: 0.9651 - val_recall: 0.9624\n",
      "Epoch 9/50\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9609 - auc: 0.9937 - loss: 0.0979 - precision: 0.9643 - recall: 0.9573 - val_accuracy: 0.9634 - val_auc: 0.9942 - val_loss: 0.0926 - val_precision: 0.9752 - val_recall: 0.9509\n",
      "Epoch 10/50\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9617 - auc: 0.9939 - loss: 0.0966 - precision: 0.9652 - recall: 0.9579 - val_accuracy: 0.9632 - val_auc: 0.9943 - val_loss: 0.0919 - val_precision: 0.9729 - val_recall: 0.9528\n",
      "Epoch 11/50\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9625 - auc: 0.9941 - loss: 0.0947 - precision: 0.9665 - recall: 0.9583 - val_accuracy: 0.9646 - val_auc: 0.9944 - val_loss: 0.0911 - val_precision: 0.9643 - val_recall: 0.9648\n",
      "Epoch 12/50\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9614 - auc: 0.9941 - loss: 0.0949 - precision: 0.9649 - recall: 0.9576 - val_accuracy: 0.9648 - val_auc: 0.9943 - val_loss: 0.0916 - val_precision: 0.9673 - val_recall: 0.9621\n",
      "Epoch 13/50\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9625 - auc: 0.9943 - loss: 0.0931 - precision: 0.9658 - recall: 0.9588 - val_accuracy: 0.9642 - val_auc: 0.9943 - val_loss: 0.0906 - val_precision: 0.9712 - val_recall: 0.9567\n",
      "Epoch 14/50\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9626 - auc: 0.9944 - loss: 0.0927 - precision: 0.9653 - recall: 0.9598 - val_accuracy: 0.9640 - val_auc: 0.9941 - val_loss: 0.0916 - val_precision: 0.9696 - val_recall: 0.9581\n",
      "Epoch 15/50\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9627 - auc: 0.9945 - loss: 0.0918 - precision: 0.9658 - recall: 0.9594 - val_accuracy: 0.9629 - val_auc: 0.9942 - val_loss: 0.0921 - val_precision: 0.9758 - val_recall: 0.9492\n",
      "Epoch 16/50\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9635 - auc: 0.9947 - loss: 0.0901 - precision: 0.9669 - recall: 0.9598 - val_accuracy: 0.9645 - val_auc: 0.9941 - val_loss: 0.0916 - val_precision: 0.9705 - val_recall: 0.9582\n",
      "Epoch 17/50\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9641 - auc: 0.9947 - loss: 0.0899 - precision: 0.9669 - recall: 0.9611 - val_accuracy: 0.9642 - val_auc: 0.9942 - val_loss: 0.0914 - val_precision: 0.9712 - val_recall: 0.9569\n",
      "Epoch 18/50\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9640 - auc: 0.9948 - loss: 0.0893 - precision: 0.9664 - recall: 0.9615 - val_accuracy: 0.9639 - val_auc: 0.9941 - val_loss: 0.0912 - val_precision: 0.9696 - val_recall: 0.9578\n",
      "Epoch 19/50\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9642 - auc: 0.9949 - loss: 0.0884 - precision: 0.9672 - recall: 0.9610 - val_accuracy: 0.9647 - val_auc: 0.9941 - val_loss: 0.0922 - val_precision: 0.9620 - val_recall: 0.9675\n",
      "Epoch 20/50\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9649 - auc: 0.9950 - loss: 0.0876 - precision: 0.9676 - recall: 0.9620 - val_accuracy: 0.9650 - val_auc: 0.9942 - val_loss: 0.0903 - val_precision: 0.9664 - val_recall: 0.9636\n",
      "Epoch 21/50\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9639 - auc: 0.9951 - loss: 0.0874 - precision: 0.9664 - recall: 0.9612 - val_accuracy: 0.9646 - val_auc: 0.9941 - val_loss: 0.0915 - val_precision: 0.9710 - val_recall: 0.9577\n",
      "Epoch 22/50\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9648 - auc: 0.9950 - loss: 0.0869 - precision: 0.9674 - recall: 0.9619 - val_accuracy: 0.9647 - val_auc: 0.9940 - val_loss: 0.0911 - val_precision: 0.9695 - val_recall: 0.9595\n",
      "Epoch 23/50\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9650 - auc: 0.9952 - loss: 0.0860 - precision: 0.9674 - recall: 0.9624 - val_accuracy: 0.9646 - val_auc: 0.9940 - val_loss: 0.0922 - val_precision: 0.9661 - val_recall: 0.9630\n",
      "Epoch 24/50\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9652 - auc: 0.9952 - loss: 0.0858 - precision: 0.9672 - recall: 0.9630 - val_accuracy: 0.9648 - val_auc: 0.9940 - val_loss: 0.0908 - val_precision: 0.9699 - val_recall: 0.9593\n",
      "Epoch 25/50\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9652 - auc: 0.9953 - loss: 0.0852 - precision: 0.9679 - recall: 0.9623 - val_accuracy: 0.9644 - val_auc: 0.9938 - val_loss: 0.0939 - val_precision: 0.9708 - val_recall: 0.9576\n",
      "Epoch 26/50\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9657 - auc: 0.9953 - loss: 0.0848 - precision: 0.9677 - recall: 0.9635 - val_accuracy: 0.9648 - val_auc: 0.9939 - val_loss: 0.0930 - val_precision: 0.9668 - val_recall: 0.9627\n",
      "Epoch 27/50\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9657 - auc: 0.9954 - loss: 0.0836 - precision: 0.9673 - recall: 0.9639 - val_accuracy: 0.9638 - val_auc: 0.9940 - val_loss: 0.0919 - val_precision: 0.9723 - val_recall: 0.9548\n",
      "Epoch 28/50\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9656 - auc: 0.9954 - loss: 0.0837 - precision: 0.9682 - recall: 0.9629 - val_accuracy: 0.9642 - val_auc: 0.9941 - val_loss: 0.0914 - val_precision: 0.9642 - val_recall: 0.9642\n",
      "Epoch 29/50\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9656 - auc: 0.9955 - loss: 0.0832 - precision: 0.9676 - recall: 0.9635 - val_accuracy: 0.9645 - val_auc: 0.9936 - val_loss: 0.0934 - val_precision: 0.9707 - val_recall: 0.9579\n",
      "Epoch 30/50\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9662 - auc: 0.9956 - loss: 0.0821 - precision: 0.9680 - recall: 0.9642 - val_accuracy: 0.9641 - val_auc: 0.9938 - val_loss: 0.0937 - val_precision: 0.9663 - val_recall: 0.9618\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n"
     ]
    }
   ],
   "source": [
    "result = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_data=(X_val_scaled, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=512,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "27e8054a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.save']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "\n",
    "dump(scaler, \"scaler.save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "811b563a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mmodel\u001b[49m.save(\u001b[33m'\u001b[39m\u001b[33mmental_health_survey_final.keras\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "model.save('mental_health_survey_final.keras')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243727df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "VALIDATION METRICS\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97     12000\n",
      "           1       0.97      0.96      0.96     11999\n",
      "\n",
      "    accuracy                           0.97     23999\n",
      "   macro avg       0.97      0.97      0.97     23999\n",
      "weighted avg       0.97      0.97      0.97     23999\n",
      "\n",
      "Validation AUC: 0.9945819026585547\n",
      "Validation Confusion Matrix:\n",
      "[[11598   402]\n",
      " [  437 11562]]\n",
      "\n",
      "TEST METRICS\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96     24364\n",
      "           1       0.96      0.96      0.96     24364\n",
      "\n",
      "    accuracy                           0.96     48728\n",
      "   macro avg       0.96      0.96      0.96     48728\n",
      "weighted avg       0.96      0.96      0.96     48728\n",
      "\n",
      "Test AUC: 0.9939832320609647\n",
      "Test Confusion Matrix:\n",
      "[[23452   912]\n",
      " [  973 23391]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "\n",
    "\n",
    "y_val_pred_proba = model.predict(X_val_scaled)\n",
    "y_val_pred = (y_val_pred_proba > 0.5).astype(int)\n",
    "\n",
    "\n",
    "y_test_pred_proba = model.predict(X_test_scaled)\n",
    "y_test_pred = (y_test_pred_proba > 0.5).astype(int)\n",
    "\n",
    "\n",
    "print(\"VALIDATION METRICS\")\n",
    "print(\"Validation Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "print(\"Validation AUC:\", roc_auc_score(y_val, y_val_pred_proba))\n",
    "print(\"Validation Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_val_pred))\n",
    "\n",
    "\n",
    "print(\"\\nTEST METRICS\")\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"Test AUC:\", roc_auc_score(y_test, y_test_pred_proba))\n",
    "print(\"Test Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b7a846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m773/773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "Metrics for Gender: Female\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96     11094\n",
      "           1       0.97      0.97      0.97     13614\n",
      "\n",
      "    accuracy                           0.97     24708\n",
      "   macro avg       0.97      0.97      0.97     24708\n",
      "weighted avg       0.97      0.97      0.97     24708\n",
      "\n",
      "\u001b[1m904/904\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "Metrics for Gender: Male\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96     13409\n",
      "           1       0.97      0.96      0.97     15504\n",
      "\n",
      "    accuracy                           0.96     28913\n",
      "   macro avg       0.96      0.96      0.96     28913\n",
      "weighted avg       0.96      0.96      0.96     28913\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "gender_columns = [col for col in X_test.columns if col.startswith(\"Gender_\")]\n",
    "\n",
    "for gender_col in gender_columns:\n",
    "    gender_label = gender_col.split(\"_\")[1]  \n",
    "    idx = X_test[gender_col] == 1            \n",
    "    y_true_group = y_test[idx]\n",
    "    y_pred_group = model.predict(X_test_scaled[idx])\n",
    "    y_pred_group = (y_pred_group > 0.5).astype(int)\n",
    "    print(f\"Metrics for Gender: {gender_label}\")\n",
    "    print(classification_report(y_true_group, y_pred_group))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af14acf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/27\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prakash Kumar\\AppData\\Local\\Temp\\ipykernel_2228\\3640646515.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test['age_group'] = pd.cut(X_test['Age'], bins=bins, labels=labels, right=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Metrics for Age Group: <18 (Samples: 839)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.77       260\n",
      "           1       0.89      0.91      0.90       579\n",
      "\n",
      "    accuracy                           0.86       839\n",
      "   macro avg       0.84      0.83      0.83       839\n",
      "weighted avg       0.86      0.86      0.86       839\n",
      "\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Metrics for Age Group: 18-29 (Samples: 8325)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.86      4243\n",
      "           1       0.84      0.89      0.87      4082\n",
      "\n",
      "    accuracy                           0.86      8325\n",
      "   macro avg       0.87      0.87      0.86      8325\n",
      "weighted avg       0.87      0.86      0.86      8325\n",
      "\n",
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Metrics for Age Group: 30-44 (Samples: 17170)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      8558\n",
      "           1       0.98      0.96      0.97      8612\n",
      "\n",
      "    accuracy                           0.97     17170\n",
      "   macro avg       0.97      0.97      0.97     17170\n",
      "weighted avg       0.97      0.97      0.97     17170\n",
      "\n",
      "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Metrics for Age Group: 45-59 (Samples: 22394)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     11303\n",
      "           1       1.00      0.99      1.00     11091\n",
      "\n",
      "    accuracy                           1.00     22394\n",
      "   macro avg       1.00      1.00      1.00     22394\n",
      "weighted avg       1.00      1.00      1.00     22394\n",
      "\n",
      "No samples in Age Group: 60+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "bins = [0, 18, 30, 45, 60, 100]\n",
    "labels = ['<18', '18-29', '30-44', '45-59', '60+']\n",
    "\n",
    "X_test['age_group'] = pd.cut(X_test['Age'], bins=bins, labels=labels, right=True)\n",
    "\n",
    "for age_group in labels:\n",
    "    idx = X_test['age_group'] == age_group\n",
    "    count_samples = idx.sum()\n",
    "    if count_samples == 0:\n",
    "        print(f\"No samples in Age Group: {age_group}\")\n",
    "        continue\n",
    "    \n",
    "    y_true_group = y_test[idx]\n",
    "    X_test_group_scaled = X_test_scaled[idx]  \n",
    "    \n",
    "    y_pred_group = model.predict(X_test_group_scaled)\n",
    "    y_pred_group = (y_pred_group > 0.5).astype(int)\n",
    "    \n",
    "    print(f\"Metrics for Age Group: {age_group} (Samples: {count_samples})\")\n",
    "    print(classification_report(y_true_group, y_pred_group, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a2c5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\n",
      "Metrics for Group: Student (Samples: 7047)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.86      3529\n",
      "           1       0.84      0.91      0.87      3518\n",
      "\n",
      "    accuracy                           0.87      7047\n",
      "   macro avg       0.87      0.87      0.87      7047\n",
      "weighted avg       0.87      0.87      0.87      7047\n",
      "\n",
      "\u001b[1m1303/1303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\n",
      "Metrics for Group: Working Professional (Samples: 41681)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     20835\n",
      "           1       0.99      0.97      0.98     20846\n",
      "\n",
      "    accuracy                           0.98     41681\n",
      "   macro avg       0.98      0.98      0.98     41681\n",
      "weighted avg       0.98      0.98      0.98     41681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "groups = ['Working Professional or Student_Student', 'Working Professional or Student_Working Professional']\n",
    "\n",
    "for group_col in groups:\n",
    "    group_label = group_col.split(\"_\", 4)[-1]  \n",
    "    \n",
    "    idx = X_test[group_col] == 1\n",
    "    count_samples = idx.sum()\n",
    "    \n",
    "    if count_samples == 0:\n",
    "        print(f\"No samples in group: {group_label}\")\n",
    "        continue\n",
    "    \n",
    "    y_true_group = y_test[idx]\n",
    "    X_test_group_scaled = X_test_scaled[idx]\n",
    "    \n",
    "    y_pred_group = model.predict(X_test_group_scaled)\n",
    "    y_pred_group = (y_pred_group > 0.5).astype(int)\n",
    "    \n",
    "    print(f\"\\nMetrics for Group: {group_label} (Samples: {count_samples})\")\n",
    "    print(classification_report(y_true_group, y_pred_group, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3a950e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Metrics for Profession: Accountant (Samples: 635)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       231\n",
      "           1       0.99      0.98      0.99       404\n",
      "\n",
      "    accuracy                           0.98       635\n",
      "   macro avg       0.98      0.98      0.98       635\n",
      "weighted avg       0.98      0.98      0.98       635\n",
      "\n",
      "No samples in profession: Analyst\n",
      "\n",
      "📊 Metrics for Profession: Architect (Samples: 3252)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98       815\n",
      "           1       1.00      0.99      0.99      2437\n",
      "\n",
      "    accuracy                           0.99      3252\n",
      "   macro avg       0.98      0.99      0.98      3252\n",
      "weighted avg       0.99      0.99      0.99      3252\n",
      "\n",
      "\n",
      "📊 Metrics for Profession: Business Analyst (Samples: 1417)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       608\n",
      "           1       0.99      0.99      0.99       809\n",
      "\n",
      "    accuracy                           0.98      1417\n",
      "   macro avg       0.98      0.98      0.98      1417\n",
      "weighted avg       0.98      0.98      0.98      1417\n",
      "\n",
      "\n",
      "📊 Metrics for Profession: Chef (Samples: 1351)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       551\n",
      "           1       1.00      0.98      0.99       800\n",
      "\n",
      "    accuracy                           0.99      1351\n",
      "   macro avg       0.98      0.99      0.99      1351\n",
      "weighted avg       0.99      0.99      0.99      1351\n",
      "\n",
      "\n",
      "📊 Metrics for Profession: Chemist (Samples: 1114)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       567\n",
      "           1       0.99      0.98      0.98       547\n",
      "\n",
      "    accuracy                           0.98      1114\n",
      "   macro avg       0.98      0.98      0.98      1114\n",
      "weighted avg       0.98      0.98      0.98      1114\n",
      "\n",
      "\n",
      "📊 Metrics for Profession: Civil Engineer (Samples: 1116)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       282\n",
      "           1       0.99      0.99      0.99       834\n",
      "\n",
      "    accuracy                           0.98      1116\n",
      "   macro avg       0.98      0.98      0.98      1116\n",
      "weighted avg       0.98      0.98      0.98      1116\n",
      "\n",
      "\n",
      "📊 Metrics for Profession: Consultant (Samples: 1878)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       822\n",
      "           1       0.99      0.98      0.99      1056\n",
      "\n",
      "    accuracy                           0.98      1878\n",
      "   macro avg       0.98      0.98      0.98      1878\n",
      "weighted avg       0.98      0.98      0.98      1878\n",
      "\n",
      "\n",
      "📊 Metrics for Profession: Content Writer (Samples: 2134)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1527\n",
      "           1       0.99      0.96      0.97       607\n",
      "\n",
      "    accuracy                           0.99      2134\n",
      "   macro avg       0.99      0.98      0.98      2134\n",
      "weighted avg       0.99      0.99      0.99      2134\n",
      "\n",
      "\n",
      "📊 Metrics for Profession: Customer Support (Samples: 853)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       374\n",
      "           1       1.00      0.98      0.99       479\n",
      "\n",
      "    accuracy                           0.99       853\n",
      "   macro avg       0.98      0.99      0.99       853\n",
      "weighted avg       0.99      0.99      0.99       853\n",
      "\n",
      "\n",
      "📊 Metrics for Profession: Data Scientist (Samples: 1226)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       436\n",
      "           1       0.99      0.98      0.99       790\n",
      "\n",
      "    accuracy                           0.99      1226\n",
      "   macro avg       0.98      0.99      0.98      1226\n",
      "weighted avg       0.99      0.99      0.99      1226\n",
      "\n",
      "\n",
      "📊 Metrics for Profession: Digital Marketer (Samples: 550)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       254\n",
      "           1       1.00      1.00      1.00       296\n",
      "\n",
      "    accuracy                           1.00       550\n",
      "   macro avg       1.00      1.00      1.00       550\n",
      "weighted avg       1.00      1.00      1.00       550\n",
      "\n",
      "\n",
      "📊 Metrics for Profession: Doctor (Samples: 1511)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       609\n",
      "           1       0.99      0.98      0.99       902\n",
      "\n",
      "    accuracy                           0.98      1511\n",
      "   macro avg       0.98      0.98      0.98      1511\n",
      "weighted avg       0.98      0.98      0.98      1511\n",
      "\n",
      "\n",
      "📊 Metrics for Profession: Educational Consultant (Samples: 1218)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       558\n",
      "           1       0.98      0.97      0.98       660\n",
      "\n",
      "    accuracy                           0.97      1218\n",
      "   macro avg       0.97      0.97      0.97      1218\n",
      "weighted avg       0.97      0.97      0.97      1218\n",
      "\n",
      "\n",
      "📊 Metrics for Profession: Electrician (Samples: 899)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       324\n",
      "           1       1.00      0.99      0.99       575\n",
      "\n",
      "    accuracy                           0.99       899\n",
      "   macro avg       0.99      0.99      0.99       899\n",
      "weighted avg       0.99      0.99      0.99       899\n",
      "\n",
      "\n",
      "📊 Metrics for Profession: Entrepreneur (Samples: 833)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       564\n",
      "           1       0.99      0.98      0.99       269\n",
      "\n",
      "    accuracy                           0.99       833\n",
      "   macro avg       0.99      0.99      0.99       833\n",
      "weighted avg       0.99      0.99      0.99       833\n",
      "\n",
      "No samples in profession: Family Consultant\n",
      "\n",
      "📊 Metrics for Profession: Financial Analyst (Samples: 1160)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       541\n",
      "           1       0.99      0.98      0.98       619\n",
      "\n",
      "    accuracy                           0.98      1160\n",
      "   macro avg       0.98      0.98      0.98      1160\n",
      "weighted avg       0.98      0.98      0.98      1160\n",
      "\n",
      "\n",
      "📊 Metrics for Profession: Graphic Designer (Samples: 1010)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       203\n",
      "           1       0.99      0.99      0.99       807\n",
      "\n",
      "    accuracy                           0.98      1010\n",
      "   macro avg       0.98      0.97      0.98      1010\n",
      "weighted avg       0.98      0.98      0.98      1010\n",
      "\n",
      "\n",
      "📊 Metrics for Profession: HR Manager (Samples: 2440)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       737\n",
      "           1       0.99      0.99      0.99      1703\n",
      "\n",
      "    accuracy                           0.99      2440\n",
      "   macro avg       0.98      0.99      0.98      2440\n",
      "weighted avg       0.99      0.99      0.99      2440\n",
      "\n",
      "\n",
      "📊 Metrics for Profession: Investment Banker (Samples: 161)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        77\n",
      "           1       0.98      0.98      0.98        84\n",
      "\n",
      "    accuracy                           0.98       161\n",
      "   macro avg       0.98      0.98      0.98       161\n",
      "weighted avg       0.98      0.98      0.98       161\n",
      "\n",
      "\n",
      "📊 Metrics for Profession: Judge (Samples: 1487)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       316\n",
      "           1       1.00      0.99      0.99      1171\n",
      "\n",
      "    accuracy                           0.99      1487\n",
      "   macro avg       0.97      0.99      0.98      1487\n",
      "weighted avg       0.99      0.99      0.99      1487\n",
      "\n",
      "\n",
      "📊 Metrics for Profession: Lawyer (Samples: 1596)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       391\n",
      "           1       1.00      0.99      0.99      1205\n",
      "\n",
      "    accuracy                           0.99      1596\n",
      "   macro avg       0.98      0.99      0.98      1596\n",
      "weighted avg       0.99      0.99      0.99      1596\n",
      "\n",
      "\n",
      "📊 Metrics for Profession: Manager (Samples: 1273)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       340\n",
      "           1       1.00      0.99      0.99       933\n",
      "\n",
      "    accuracy                           0.99      1273\n",
      "   macro avg       0.99      0.99      0.99      1273\n",
      "weighted avg       0.99      0.99      0.99      1273\n",
      "\n",
      "\n",
      "📊 Metrics for Profession: Marketing Manager (Samples: 989)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       368\n",
      "           1       0.99      0.98      0.99       621\n",
      "\n",
      "    accuracy                           0.98       989\n",
      "   macro avg       0.98      0.98      0.98       989\n",
      "weighted avg       0.98      0.98      0.98       989\n",
      "\n",
      "\n",
      "📊 Metrics for Profession: Mechanical Engineer (Samples: 920)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94       213\n",
      "           1       0.99      0.98      0.98       707\n",
      "\n",
      "    accuracy                           0.97       920\n",
      "   macro avg       0.96      0.97      0.96       920\n",
      "weighted avg       0.97      0.97      0.97       920\n",
      "\n",
      "\n",
      "📊 Metrics for Profession: Pharmacist (Samples: 1374)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       737\n",
      "           1       1.00      0.99      0.99       637\n",
      "\n",
      "    accuracy                           0.99      1374\n",
      "   macro avg       0.99      0.99      0.99      1374\n",
      "weighted avg       0.99      0.99      0.99      1374\n",
      "\n",
      "\n",
      "📊 Metrics for Profession: Pilot (Samples: 1216)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       367\n",
      "           1       0.99      0.99      0.99       849\n",
      "\n",
      "    accuracy                           0.98      1216\n",
      "   macro avg       0.98      0.98      0.98      1216\n",
      "weighted avg       0.98      0.98      0.98      1216\n",
      "\n",
      "\n",
      "📊 Metrics for Profession: Plumber (Samples: 1079)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98       310\n",
      "           1       1.00      0.98      0.99       769\n",
      "\n",
      "    accuracy                           0.99      1079\n",
      "   macro avg       0.98      0.99      0.98      1079\n",
      "weighted avg       0.99      0.99      0.99      1079\n",
      "\n",
      "\n",
      "📊 Metrics for Profession: Research Analyst (Samples: 411)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       131\n",
      "           1       0.99      0.98      0.99       280\n",
      "\n",
      "    accuracy                           0.98       411\n",
      "   macro avg       0.98      0.98      0.98       411\n",
      "weighted avg       0.98      0.98      0.98       411\n",
      "\n",
      "\n",
      "📊 Metrics for Profession: Researcher (Samples: 1031)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       458\n",
      "           1       0.99      0.99      0.99       573\n",
      "\n",
      "    accuracy                           0.99      1031\n",
      "   macro avg       0.99      0.99      0.99      1031\n",
      "weighted avg       0.99      0.99      0.99      1031\n",
      "\n",
      "\n",
      "📊 Metrics for Profession: Sales Executive (Samples: 830)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       330\n",
      "           1       0.99      0.98      0.99       500\n",
      "\n",
      "    accuracy                           0.98       830\n",
      "   macro avg       0.98      0.98      0.98       830\n",
      "weighted avg       0.98      0.98      0.98       830\n",
      "\n",
      "\n",
      "📊 Metrics for Profession: Software Engineer (Samples: 490)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       294\n",
      "           1       0.96      0.97      0.96       196\n",
      "\n",
      "    accuracy                           0.97       490\n",
      "   macro avg       0.97      0.97      0.97       490\n",
      "weighted avg       0.97      0.97      0.97       490\n",
      "\n",
      "\n",
      "📊 Metrics for Profession: Student (Samples: 7039)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.86      3527\n",
      "           1       0.84      0.91      0.87      3512\n",
      "\n",
      "    accuracy                           0.87      7039\n",
      "   macro avg       0.87      0.87      0.87      7039\n",
      "weighted avg       0.87      0.87      0.87      7039\n",
      "\n",
      "\n",
      "📊 Metrics for Profession: Teacher (Samples: 11914)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      4762\n",
      "           1       0.99      0.99      0.99      7152\n",
      "\n",
      "    accuracy                           0.99     11914\n",
      "   macro avg       0.99      0.99      0.99     11914\n",
      "weighted avg       0.99      0.99      0.99     11914\n",
      "\n",
      "\n",
      "📊 Metrics for Profession: Travel Consultant (Samples: 657)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       355\n",
      "           1       0.99      0.96      0.97       302\n",
      "\n",
      "    accuracy                           0.98       657\n",
      "   macro avg       0.98      0.98      0.98       657\n",
      "weighted avg       0.98      0.98      0.98       657\n",
      "\n",
      "\n",
      "📊 Metrics for Profession: UX/UI Designer (Samples: 688)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       256\n",
      "           1       1.00      0.98      0.99       432\n",
      "\n",
      "    accuracy                           0.99       688\n",
      "   macro avg       0.98      0.99      0.98       688\n",
      "weighted avg       0.99      0.99      0.99       688\n",
      "\n",
      "No samples in profession: Unemployed\n",
      "\n",
      "📊 Metrics for Profession: Unknown (Samples: 5766)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90      1130\n",
      "           1       0.98      0.97      0.98      4636\n",
      "\n",
      "    accuracy                           0.96      5766\n",
      "   macro avg       0.93      0.95      0.94      5766\n",
      "weighted avg       0.96      0.96      0.96      5766\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "profession_cols = [col for col in X_test.columns if col.startswith(\"Profession_\")]\n",
    "\n",
    "for prof_col in profession_cols:\n",
    "    prof_label = prof_col.replace(\"Profession_\", \"\")  \n",
    "    \n",
    "    \n",
    "    idx = X_test[prof_col] == 1\n",
    "    count_samples = idx.sum()\n",
    "    \n",
    "    if count_samples == 0:\n",
    "        print(f\"No samples in profession: {prof_label}\")\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    y_true_prof = y_test[idx]\n",
    "    \n",
    "    X_test_prof_scaled = X_test_scaled[idx]\n",
    "    \n",
    "    \n",
    "    y_pred_prof = model.predict(X_test_prof_scaled, verbose=0)\n",
    "    y_pred_prof = (y_pred_prof > 0.5).astype(int)\n",
    "    \n",
    "    \n",
    "    print(f\"\\n📊 Metrics for Profession: {prof_label} (Samples: {count_samples})\")\n",
    "    print(classification_report(y_true_prof, y_pred_prof, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271f9897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "📊 Metrics for Degree: BA (Samples: 1528)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       719\n",
      "           1       0.98      0.96      0.97       809\n",
      "\n",
      "    accuracy                           0.97      1528\n",
      "   macro avg       0.97      0.97      0.97      1528\n",
      "weighted avg       0.97      0.97      0.97      1528\n",
      "\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "📊 Metrics for Degree: BARCH (Samples: 4069)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      1615\n",
      "           1       0.99      0.98      0.98      2454\n",
      "\n",
      "    accuracy                           0.98      4069\n",
      "   macro avg       0.98      0.98      0.98      4069\n",
      "weighted avg       0.98      0.98      0.98      4069\n",
      "\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "📊 Metrics for Degree: BBA (Samples: 2400)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       959\n",
      "           1       0.98      0.97      0.98      1441\n",
      "\n",
      "    accuracy                           0.97      2400\n",
      "   macro avg       0.97      0.97      0.97      2400\n",
      "weighted avg       0.97      0.97      0.97      2400\n",
      "\n",
      "No samples in group: BBARCH\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "📊 Metrics for Degree: BCA (Samples: 2426)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95      1002\n",
      "           1       0.97      0.96      0.96      1424\n",
      "\n",
      "    accuracy                           0.95      2426\n",
      "   macro avg       0.95      0.95      0.95      2426\n",
      "weighted avg       0.95      0.95      0.95      2426\n",
      "\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "📊 Metrics for Degree: BCOM (Samples: 3001)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1469\n",
      "           1       0.97      0.97      0.97      1532\n",
      "\n",
      "    accuracy                           0.97      3001\n",
      "   macro avg       0.97      0.97      0.97      3001\n",
      "weighted avg       0.97      0.97      0.97      3001\n",
      "\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "📊 Metrics for Degree: BE (Samples: 2030)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       568\n",
      "           1       0.98      0.98      0.98      1462\n",
      "\n",
      "    accuracy                           0.97      2030\n",
      "   macro avg       0.96      0.96      0.96      2030\n",
      "weighted avg       0.97      0.97      0.97      2030\n",
      "\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "📊 Metrics for Degree: BED (Samples: 4312)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      2223\n",
      "           1       0.97      0.97      0.97      2089\n",
      "\n",
      "    accuracy                           0.97      4312\n",
      "   macro avg       0.97      0.97      0.97      4312\n",
      "weighted avg       0.97      0.97      0.97      4312\n",
      "\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "📊 Metrics for Degree: BHM (Samples: 1831)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       813\n",
      "           1       0.97      0.97      0.97      1018\n",
      "\n",
      "    accuracy                           0.97      1831\n",
      "   macro avg       0.97      0.97      0.97      1831\n",
      "weighted avg       0.97      0.97      0.97      1831\n",
      "\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "📊 Metrics for Degree: BPHARM (Samples: 2748)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1121\n",
      "           1       0.98      0.98      0.98      1627\n",
      "\n",
      "    accuracy                           0.98      2748\n",
      "   macro avg       0.98      0.98      0.98      2748\n",
      "weighted avg       0.98      0.98      0.98      2748\n",
      "\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "📊 Metrics for Degree: BSC (Samples: 2463)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96       893\n",
      "           1       0.97      0.99      0.98      1570\n",
      "\n",
      "    accuracy                           0.97      2463\n",
      "   macro avg       0.97      0.97      0.97      2463\n",
      "weighted avg       0.97      0.97      0.97      2463\n",
      "\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "📊 Metrics for Degree: BTECH (Samples: 2019)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       803\n",
      "           1       0.97      0.97      0.97      1216\n",
      "\n",
      "    accuracy                           0.97      2019\n",
      "   macro avg       0.97      0.97      0.97      2019\n",
      "weighted avg       0.97      0.97      0.97      2019\n",
      "\n",
      "No samples in group: CLASS 11\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\n",
      "📊 Metrics for Degree: CLASS 12 (Samples: 7143)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89      1785\n",
      "           1       0.96      0.97      0.96      5358\n",
      "\n",
      "    accuracy                           0.95      7143\n",
      "   macro avg       0.93      0.93      0.93      7143\n",
      "weighted avg       0.95      0.95      0.95      7143\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\n",
      "📊 Metrics for Degree: LED (Samples: 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         1\n",
      "   macro avg       1.00      1.00      1.00         1\n",
      "weighted avg       1.00      1.00      1.00         1\n",
      "\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "📊 Metrics for Degree: LLB (Samples: 3105)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       729\n",
      "           1       0.99      0.98      0.99      2376\n",
      "\n",
      "    accuracy                           0.98      3105\n",
      "   macro avg       0.97      0.98      0.97      3105\n",
      "weighted avg       0.98      0.98      0.98      3105\n",
      "\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "📊 Metrics for Degree: LLM (Samples: 2910)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       862\n",
      "           1       0.99      0.98      0.99      2048\n",
      "\n",
      "    accuracy                           0.98      2910\n",
      "   macro avg       0.98      0.98      0.98      2910\n",
      "weighted avg       0.98      0.98      0.98      2910\n",
      "\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "📊 Metrics for Degree: MA (Samples: 1876)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       543\n",
      "           1       0.98      0.99      0.99      1333\n",
      "\n",
      "    accuracy                           0.98      1876\n",
      "   macro avg       0.98      0.97      0.97      1876\n",
      "weighted avg       0.98      0.98      0.98      1876\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\n",
      "📊 Metrics for Degree: MARCH (Samples: 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         1\n",
      "   macro avg       1.00      1.00      1.00         1\n",
      "weighted avg       1.00      1.00      1.00         1\n",
      "\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "📊 Metrics for Degree: MBA (Samples: 1446)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       725\n",
      "           1       0.96      0.97      0.97       721\n",
      "\n",
      "    accuracy                           0.97      1446\n",
      "   macro avg       0.97      0.97      0.97      1446\n",
      "weighted avg       0.97      0.97      0.97      1446\n",
      "\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "📊 Metrics for Degree: MBBS (Samples: 1272)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       539\n",
      "           1       0.97      0.98      0.98       733\n",
      "\n",
      "    accuracy                           0.97      1272\n",
      "   macro avg       0.97      0.97      0.97      1272\n",
      "weighted avg       0.97      0.97      0.97      1272\n",
      "\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "📊 Metrics for Degree: MCA (Samples: 2506)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       999\n",
      "           1       0.98      0.98      0.98      1507\n",
      "\n",
      "    accuracy                           0.98      2506\n",
      "   macro avg       0.98      0.98      0.98      2506\n",
      "weighted avg       0.98      0.98      0.98      2506\n",
      "\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "📊 Metrics for Degree: MCOM (Samples: 1545)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       575\n",
      "           1       0.98      0.97      0.98       970\n",
      "\n",
      "    accuracy                           0.97      1545\n",
      "   macro avg       0.97      0.97      0.97      1545\n",
      "weighted avg       0.97      0.97      0.97      1545\n",
      "\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "📊 Metrics for Degree: MD (Samples: 1904)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       649\n",
      "           1       0.98      0.98      0.98      1255\n",
      "\n",
      "    accuracy                           0.97      1904\n",
      "   macro avg       0.97      0.97      0.97      1904\n",
      "weighted avg       0.97      0.97      0.97      1904\n",
      "\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "📊 Metrics for Degree: ME (Samples: 1831)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       707\n",
      "           1       0.99      0.99      0.99      1124\n",
      "\n",
      "    accuracy                           0.99      1831\n",
      "   macro avg       0.98      0.99      0.98      1831\n",
      "weighted avg       0.99      0.99      0.99      1831\n",
      "\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "📊 Metrics for Degree: MED (Samples: 1958)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1036\n",
      "           1       0.98      0.98      0.98       922\n",
      "\n",
      "    accuracy                           0.98      1958\n",
      "   macro avg       0.98      0.98      0.98      1958\n",
      "weighted avg       0.98      0.98      0.98      1958\n",
      "\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "📊 Metrics for Degree: MHM (Samples: 1781)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       638\n",
      "           1       0.99      0.98      0.98      1143\n",
      "\n",
      "    accuracy                           0.98      1781\n",
      "   macro avg       0.98      0.98      0.98      1781\n",
      "weighted avg       0.98      0.98      0.98      1781\n",
      "\n",
      "No samples in group: MPA\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "📊 Metrics for Degree: MPHARM (Samples: 1642)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       851\n",
      "           1       0.97      0.96      0.97       791\n",
      "\n",
      "    accuracy                           0.97      1642\n",
      "   macro avg       0.97      0.97      0.97      1642\n",
      "weighted avg       0.97      0.97      0.97      1642\n",
      "\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "📊 Metrics for Degree: MSC (Samples: 2309)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       888\n",
      "           1       0.98      0.98      0.98      1421\n",
      "\n",
      "    accuracy                           0.98      2309\n",
      "   macro avg       0.98      0.97      0.97      2309\n",
      "weighted avg       0.98      0.98      0.98      2309\n",
      "\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "📊 Metrics for Degree: MTECH (Samples: 1561)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96       785\n",
      "           1       0.97      0.96      0.96       776\n",
      "\n",
      "    accuracy                           0.96      1561\n",
      "   macro avg       0.96      0.96      0.96      1561\n",
      "weighted avg       0.96      0.96      0.96      1561\n",
      "\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "📊 Metrics for Degree: PHD (Samples: 1918)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       554\n",
      "           1       0.99      0.98      0.98      1364\n",
      "\n",
      "    accuracy                           0.98      1918\n",
      "   macro avg       0.97      0.98      0.97      1918\n",
      "weighted avg       0.98      0.98      0.98      1918\n",
      "\n",
      "No samples in group: PPHARM\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\n",
      "📊 Metrics for Degree: RCA (Samples: 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         1\n",
      "   macro avg       1.00      1.00      1.00         1\n",
      "weighted avg       1.00      1.00      1.00         1\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\n",
      "📊 Metrics for Degree: UNKNOWN (Samples: 21)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.93      0.85        15\n",
      "           1       0.67      0.33      0.44         6\n",
      "\n",
      "    accuracy                           0.76        21\n",
      "   macro avg       0.72      0.63      0.65        21\n",
      "weighted avg       0.75      0.76      0.73        21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "degree_groups = [col for col in X_test.columns if col.startswith(\"Degree_\")]\n",
    "\n",
    "for group_col in degree_groups:\n",
    "    group_label = group_col.replace(\"Degree_\", \"\")  \n",
    "    \n",
    "    idx = X_test[group_col] == 1\n",
    "    count_samples = idx.sum()\n",
    "    \n",
    "    if count_samples == 0:\n",
    "        print(f\"No samples in group: {group_label}\")\n",
    "        continue\n",
    "    \n",
    "    y_true_group = y_test[idx]\n",
    "    X_test_group_scaled = X_test_scaled[idx]\n",
    "    \n",
    "    y_pred_group = model.predict(X_test_group_scaled)\n",
    "    y_pred_group = (y_pred_group > 0.5).astype(int)\n",
    "    \n",
    "    print(f\"\\n📊 Metrics for Degree: {group_label} (Samples: {count_samples})\")\n",
    "    print(classification_report(y_true_group, y_pred_group, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a53c201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "📊 Metrics for City: Agra (Samples: 2772)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       892\n",
      "           1       0.98      0.97      0.98      1880\n",
      "\n",
      "    accuracy                           0.97      2772\n",
      "   macro avg       0.96      0.96      0.96      2772\n",
      "weighted avg       0.97      0.97      0.97      2772\n",
      "\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "📊 Metrics for City: Ahmedabad (Samples: 3190)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96       916\n",
      "           1       0.98      0.98      0.98      2274\n",
      "\n",
      "    accuracy                           0.97      3190\n",
      "   macro avg       0.97      0.97      0.97      3190\n",
      "weighted avg       0.97      0.97      0.97      3190\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "📊 Metrics for City: Bangalore (Samples: 1720)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       712\n",
      "           1       0.98      0.97      0.97      1008\n",
      "\n",
      "    accuracy                           0.97      1720\n",
      "   macro avg       0.97      0.97      0.97      1720\n",
      "weighted avg       0.97      0.97      0.97      1720\n",
      "\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "📊 Metrics for City: Bhopal (Samples: 1764)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       597\n",
      "           1       0.97      0.97      0.97      1167\n",
      "\n",
      "    accuracy                           0.96      1764\n",
      "   macro avg       0.96      0.95      0.95      1764\n",
      "weighted avg       0.96      0.96      0.96      1764\n",
      "\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "📊 Metrics for City: Chennai (Samples: 1391)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       713\n",
      "           1       0.94      0.96      0.95       678\n",
      "\n",
      "    accuracy                           0.95      1391\n",
      "   macro avg       0.95      0.95      0.95      1391\n",
      "weighted avg       0.95      0.95      0.95      1391\n",
      "\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "📊 Metrics for City: Delhi (Samples: 1323)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       581\n",
      "           1       0.96      0.98      0.97       742\n",
      "\n",
      "    accuracy                           0.97      1323\n",
      "   macro avg       0.97      0.97      0.97      1323\n",
      "weighted avg       0.97      0.97      0.97      1323\n",
      "\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "📊 Metrics for City: Faridabad (Samples: 1396)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       613\n",
      "           1       0.98      0.97      0.98       783\n",
      "\n",
      "    accuracy                           0.97      1396\n",
      "   macro avg       0.97      0.97      0.97      1396\n",
      "weighted avg       0.97      0.97      0.97      1396\n",
      "\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "📊 Metrics for City: Ghaziabad (Samples: 2307)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96       632\n",
      "           1       0.99      0.98      0.99      1675\n",
      "\n",
      "    accuracy                           0.98      2307\n",
      "   macro avg       0.97      0.98      0.97      2307\n",
      "weighted avg       0.98      0.98      0.98      2307\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\n",
      "📊 Metrics for City: Gurgaon (Samples: 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         1\n",
      "   macro avg       1.00      1.00      1.00         1\n",
      "weighted avg       1.00      1.00      1.00         1\n",
      "\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "📊 Metrics for City: Hyderabad (Samples: 2340)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95       750\n",
      "           1       0.97      0.98      0.98      1590\n",
      "\n",
      "    accuracy                           0.97      2340\n",
      "   macro avg       0.96      0.96      0.96      2340\n",
      "weighted avg       0.97      0.97      0.97      2340\n",
      "\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "📊 Metrics for City: Indore (Samples: 2034)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       889\n",
      "           1       0.97      0.96      0.97      1145\n",
      "\n",
      "    accuracy                           0.96      2034\n",
      "   macro avg       0.96      0.96      0.96      2034\n",
      "weighted avg       0.96      0.96      0.96      2034\n",
      "\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "📊 Metrics for City: Jaipur (Samples: 1907)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       815\n",
      "           1       0.97      0.97      0.97      1092\n",
      "\n",
      "    accuracy                           0.97      1907\n",
      "   macro avg       0.97      0.97      0.97      1907\n",
      "weighted avg       0.97      0.97      0.97      1907\n",
      "\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "📊 Metrics for City: Kalyan (Samples: 2829)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1163\n",
      "           1       0.97      0.97      0.97      1666\n",
      "\n",
      "    accuracy                           0.97      2829\n",
      "   macro avg       0.97      0.97      0.97      2829\n",
      "weighted avg       0.97      0.97      0.97      2829\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "📊 Metrics for City: Kanpur (Samples: 1725)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       849\n",
      "           1       0.97      0.97      0.97       876\n",
      "\n",
      "    accuracy                           0.97      1725\n",
      "   macro avg       0.97      0.97      0.97      1725\n",
      "weighted avg       0.97      0.97      0.97      1725\n",
      "\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "📊 Metrics for City: Kolkata (Samples: 2396)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       983\n",
      "           1       0.98      0.98      0.98      1413\n",
      "\n",
      "    accuracy                           0.98      2396\n",
      "   macro avg       0.98      0.97      0.98      2396\n",
      "weighted avg       0.98      0.98      0.98      2396\n",
      "\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "📊 Metrics for City: Lucknow (Samples: 2175)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       728\n",
      "           1       0.98      0.97      0.97      1447\n",
      "\n",
      "    accuracy                           0.97      2175\n",
      "   macro avg       0.96      0.96      0.96      2175\n",
      "weighted avg       0.97      0.97      0.97      2175\n",
      "\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "📊 Metrics for City: Ludhiana (Samples: 2229)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96       932\n",
      "           1       0.98      0.97      0.97      1297\n",
      "\n",
      "    accuracy                           0.97      2229\n",
      "   macro avg       0.97      0.97      0.97      2229\n",
      "weighted avg       0.97      0.97      0.97      2229\n",
      "\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "📊 Metrics for City: Meerut (Samples: 2510)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1053\n",
      "           1       0.98      0.98      0.98      1457\n",
      "\n",
      "    accuracy                           0.98      2510\n",
      "   macro avg       0.98      0.98      0.98      2510\n",
      "weighted avg       0.98      0.98      0.98      2510\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\n",
      "📊 Metrics for City: Morena (Samples: 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         1\n",
      "   macro avg       1.00      1.00      1.00         1\n",
      "weighted avg       1.00      1.00      1.00         1\n",
      "\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "📊 Metrics for City: Mumbai (Samples: 2043)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       966\n",
      "           1       0.98      0.97      0.98      1077\n",
      "\n",
      "    accuracy                           0.98      2043\n",
      "   macro avg       0.98      0.98      0.98      2043\n",
      "weighted avg       0.98      0.98      0.98      2043\n",
      "\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "📊 Metrics for City: Nagpur (Samples: 1833)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       759\n",
      "           1       0.98      0.98      0.98      1074\n",
      "\n",
      "    accuracy                           0.97      1833\n",
      "   macro avg       0.97      0.97      0.97      1833\n",
      "weighted avg       0.97      0.97      0.97      1833\n",
      "\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "📊 Metrics for City: Nashik (Samples: 1821)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       597\n",
      "           1       0.99      0.99      0.99      1224\n",
      "\n",
      "    accuracy                           0.98      1821\n",
      "   macro avg       0.98      0.98      0.98      1821\n",
      "weighted avg       0.98      0.98      0.98      1821\n",
      "\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "📊 Metrics for City: Patna (Samples: 3031)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97      1032\n",
      "           1       0.99      0.98      0.98      1999\n",
      "\n",
      "    accuracy                           0.98      3031\n",
      "   macro avg       0.97      0.98      0.97      3031\n",
      "weighted avg       0.98      0.98      0.98      3031\n",
      "\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "📊 Metrics for City: Pune (Samples: 2336)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       993\n",
      "           1       0.98      0.97      0.98      1343\n",
      "\n",
      "    accuracy                           0.97      2336\n",
      "   macro avg       0.97      0.97      0.97      2336\n",
      "weighted avg       0.97      0.97      0.97      2336\n",
      "\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "📊 Metrics for City: Rajkot (Samples: 2656)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       942\n",
      "           1       0.98      0.98      0.98      1714\n",
      "\n",
      "    accuracy                           0.97      2656\n",
      "   macro avg       0.97      0.97      0.97      2656\n",
      "weighted avg       0.97      0.97      0.97      2656\n",
      "\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "📊 Metrics for City: Srinagar (Samples: 2551)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       917\n",
      "           1       0.98      0.97      0.98      1634\n",
      "\n",
      "    accuracy                           0.97      2551\n",
      "   macro avg       0.97      0.97      0.97      2551\n",
      "weighted avg       0.97      0.97      0.97      2551\n",
      "\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "📊 Metrics for City: Surat (Samples: 2462)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96       846\n",
      "           1       0.98      0.98      0.98      1616\n",
      "\n",
      "    accuracy                           0.97      2462\n",
      "   macro avg       0.97      0.97      0.97      2462\n",
      "weighted avg       0.97      0.97      0.97      2462\n",
      "\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "📊 Metrics for City: Thane (Samples: 1915)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       802\n",
      "           1       0.96      0.97      0.97      1113\n",
      "\n",
      "    accuracy                           0.96      1915\n",
      "   macro avg       0.96      0.96      0.96      1915\n",
      "weighted avg       0.96      0.96      0.96      1915\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\n",
      "📊 Metrics for City: Unknown (Samples: 24)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94        19\n",
      "           1       0.71      1.00      0.83         5\n",
      "\n",
      "    accuracy                           0.92        24\n",
      "   macro avg       0.86      0.95      0.89        24\n",
      "weighted avg       0.94      0.92      0.92        24\n",
      "\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "📊 Metrics for City: Vadodara (Samples: 2716)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       839\n",
      "           1       0.99      0.99      0.99      1877\n",
      "\n",
      "    accuracy                           0.98      2716\n",
      "   macro avg       0.98      0.98      0.98      2716\n",
      "weighted avg       0.98      0.98      0.98      2716\n",
      "\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "📊 Metrics for City: Varanasi (Samples: 2691)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96       829\n",
      "           1       0.98      0.98      0.98      1862\n",
      "\n",
      "    accuracy                           0.98      2691\n",
      "   macro avg       0.97      0.97      0.97      2691\n",
      "weighted avg       0.98      0.98      0.98      2691\n",
      "\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "📊 Metrics for City: Vasai-Virar (Samples: 2525)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      1032\n",
      "           1       0.97      0.98      0.97      1493\n",
      "\n",
      "    accuracy                           0.97      2525\n",
      "   macro avg       0.97      0.97      0.97      2525\n",
      "weighted avg       0.97      0.97      0.97      2525\n",
      "\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "📊 Metrics for City: Visakhapatnam (Samples: 2287)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97       929\n",
      "           1       0.98      0.97      0.98      1358\n",
      "\n",
      "    accuracy                           0.97      2287\n",
      "   macro avg       0.97      0.97      0.97      2287\n",
      "weighted avg       0.97      0.97      0.97      2287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "city_groups = [col for col in X_test.columns if col.startswith(\"City_\")]\n",
    "\n",
    "for city_col in city_groups:\n",
    "    city_label = city_col.split(\"_\", 1)[-1] \n",
    "    \n",
    "    \n",
    "    idx = X_test[city_col] == 1\n",
    "    count_samples = idx.sum()\n",
    "    \n",
    "    if count_samples == 0:\n",
    "        print(f\"No samples in City: {city_label}\")\n",
    "        continue\n",
    "    \n",
    "    y_true_group = y_test[idx]\n",
    "    X_test_group_scaled = X_test_scaled[idx]\n",
    "    \n",
    "    \n",
    "    y_pred_group = model.predict(X_test_group_scaled)\n",
    "    y_pred_group = (y_pred_group > 0.5).astype(int)\n",
    "    \n",
    "    print(f\"\\n📊 Metrics for City: {city_label} (Samples: {count_samples})\")\n",
    "    print(classification_report(y_true_group, y_pred_group, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "571d3728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140695, 137)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "19c0604c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93800, 19)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e25b248",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = df_test[\"id\"].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a62db5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop(columns=[\"Name\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "03605d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender ['Male' 'Female']\n",
      "City ['Visakhapatnam' 'Kolkata' 'Jaipur' 'Rajkot' 'Kalyan' 'Mumbai' 'Surat'\n",
      " 'Srinagar' 'Delhi' 'Lucknow' 'Thane' 'Meerut' 'Nagpur' 'Ghaziabad'\n",
      " 'Chennai' 'Varanasi' 'Indore' 'Pune' 'Hyderabad' 'Kanpur' 'Nashik'\n",
      " 'Bhopal' 'Faridabad' 'Bangalore' 'Vasai-Virar' 'Ludhiana' 'Patna'\n",
      " 'Vadodara' 'Ahmedabad' 'Agra' 'Malyan' 'Pratyush' 'Vidya'\n",
      " 'Less than 5 hours' 'Aditi' 'Keshav' 'Nalini' 'Mhopal' 'Avni' 'Ira'\n",
      " 'Vaishnavi' 'Bhavna' 'Lawyer' 'Thani' 'Hrithik' 'City' 'Unaly'\n",
      " 'Is Kanpur' 'Golkata' 'Less Delhi' 'Sara' 'Saurav' 'Vikram' 'Parth'\n",
      " 'Siddhesh' 'Vaikot' 'Leela' 'Chemist' 'San Vasai-Virar' 'No' 'More Delhi'\n",
      " 'Saanvi' 'Pratham' 'Vidhi' 'Abhinav' 'Rolkata' 'Ghopal' 'No.12']\n",
      "Working Professional or Student ['Working Professional' 'Student']\n",
      "Profession ['Judge' 'Educational Consultant' 'Teacher' nan 'Customer Support'\n",
      " 'Chemist' 'Content Writer' 'Consultant' 'HR Manager' 'Research Analyst'\n",
      " 'Digital Marketer' 'Electrician' 'Marketing Manager' 'Plumber'\n",
      " 'Pharmacist' 'Lawyer' 'Pilot' 'Architect' 'Chef' 'Graphic Designer'\n",
      " 'Entrepreneur' 'Manager' 'Mechanical Engineer' 'Software Engineer'\n",
      " 'Travel Consultant' 'Finanancial Analyst' 'Financial Analyst' 'Doctor'\n",
      " 'Business Analyst' 'UX/UI Designer' 'Sales Executive' 'Data Scientist'\n",
      " 'Accountant' 'Researcher' 'Civil Engineer' 'Investment Banker'\n",
      " 'Unhealthy' 'B.Ed' 'Student' 'Working Professional' '3M' 'ME' 'B.Pharm'\n",
      " '24th' 'Manvi' 'Yogesh' 'Samar' 'Surat' 'PhD' 'M.Ed' 'MD' 'Name' 'MCA'\n",
      " 'Simran' 'Analyst' 'Profession' 'Unemployed' 'BBA' 'M.Tech' 'LLM'\n",
      " 'Surgeon' 'No' 'Unveil' 'City Consultant' 'M.Pharm']\n",
      "Sleep Duration ['Less than 5 hours' '7-8 hours' 'More than 8 hours' '5-6 hours' '0'\n",
      " 'Meerut' '9-5 hours' '6-7 hours' '60-65 hours' 'Vivan' '3-4 hours'\n",
      " '1-6 hours' '9-5' 'Unhealthy' '8-9 hours' '4-5 hours' 'than 5 hours'\n",
      " '9-6 hours' '1-2 hours' '8-89 hours'\n",
      " 'Have_you_ever_had_suicidal_thoughts' '20-21 hours' '10-6 hours'\n",
      " '1-3 hours' '6 hours' '50-75 hours' '4-6 hours' '2-3 hours' '9-11 hours'\n",
      " '9-10 hours' '3-6 hours']\n",
      "Dietary Habits ['Moderate' 'Healthy' 'Unhealthy' 'More Healthy' 'No' 'Indoor' 'Prachi'\n",
      " nan 'Male' 'Less Healthy' 'Mealy' 'Resistant' 'MCA' '5 Healthy'\n",
      " 'Academic' 'Educational' 'Soham' '5 Unhealthy' 'Vivaan' 'Raghav' '1.0'\n",
      " 'Naina' 'Kolkata']\n",
      "Degree ['LLB' 'B.Ed' 'B.Arch' 'BSc' 'BCA' 'B.Com' 'MA' 'BA' 'BBA' 'Class 12' 'MD'\n",
      " 'MBA' 'M.Ed' 'M.Pharm' 'BHM' 'LLM' 'PhD' 'M.Com' 'BE' 'MBBS' 'B.Tech'\n",
      " 'ME' 'MCA' 'B.Pharm' 'MHM' 'M.Tech' 'BTech' 'MSc' 'BArch' 'B. Gender'\n",
      " 'B.Study_Hours' 'Advait' 'M.Arch' 'A.Ed' 'Mechanical Engineer' 'B.H'\n",
      " 'B.Sc' 'B' 'M.UI' 'Vibha' 'B BCA' 'B.Press' 'BPharm' 'Gagan' 'MPharm'\n",
      " 'Travel Consultant' '5.65' 'Business Analyst' 'Eshita' 'B_Com' 'Navya'\n",
      " 'B._Pharm' 'Pune' 'Bian' 'B.M.Com' 'Kavya' 'M.M.Ed' 'S.Pharm' 'Vrinda'\n",
      " 'M' 'E.Ed' '3.0' 'Moham' 'B.BA' nan 'I.Ed' 'Degree' 'Magan' 'B B.Tech'\n",
      " 'M.B.Ed' 'Bhopal' 'B Financial Analyst' 'GCA' 'G.Ed' 'Rupak' 'RCA' 'B.CA'\n",
      " 'PCA' 'J.Ed' 'BH' 'BEd' '8.95' 'Aadhya' '20' 'Banchal' 'M.' 'K.Ed' 'BHCA']\n",
      "Have you ever had suicidal thoughts ? ['No' 'Yes']\n",
      "Family History of Mental Illness ['Yes' 'No']\n"
     ]
    }
   ],
   "source": [
    "for i in df_test.select_dtypes(include = [\"object\"]).columns:\n",
    "\t\t\t print(i, df_test[i].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f845361e",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_cities_test = {\n",
    "    \"Pratyush\",\"Vidya\",\"Less than 5 hours\",\"Aditi\",\"Keshav\",\"Nalini\",\n",
    "    \"Avni\",\"Ira\",\"Vaishnavi\",\"Bhavna\",\"Lawyer\",\"Hrithik\",\"City\",\"Is Kanpur\",\n",
    "    \"Less Delhi\",\"Sara\",\"Saurav\",\"Vikram\",\"Parth\",\"Siddhesh\",\"Vaikot\",\n",
    "    \"Leela\",\"Chemist\",\"No\",\"More Delhi\",\"Saanvi\",\"Pratham\",\"Vidhi\",\n",
    "    \"Abhinav\",\"No.12\",\"Unaly\"\n",
    "}\n",
    "\n",
    "df_test['City'] = df_test['City'].apply(lambda x: \"Unknown\" if x in invalid_cities_test else x)\n",
    "\n",
    "city_corrections_test = {\n",
    "    \"Malyan\": \"Kalyan\",\n",
    "    \"Mhopal\": \"Bhopal\",\n",
    "    \"Ghopal\": \"Bhopal\",\n",
    "    \"Thani\": \"Thane\",\n",
    "    \"Golkata\": \"Kolkata\",\n",
    "    \"Rolkata\": \"Kolkata\",\n",
    "    \"San Vasai-Virar\": \"Vasai-Virar\"\n",
    "}\n",
    "\n",
    "df_test['City'] = df_test['City'].replace(city_corrections_test)\n",
    "df_test = df_test.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a075bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                           0\n",
       "Gender                                       0\n",
       "Age                                          0\n",
       "City                                         0\n",
       "Working Professional or Student              0\n",
       "Profession                               24632\n",
       "Academic Pressure                        75033\n",
       "Work Pressure                            18778\n",
       "CGPA                                     75034\n",
       "Study Satisfaction                       75033\n",
       "Job Satisfaction                         18774\n",
       "Sleep Duration                               0\n",
       "Dietary Habits                               5\n",
       "Degree                                       2\n",
       "Have you ever had suicidal thoughts ?        0\n",
       "Work/Study Hours                             0\n",
       "Financial Stress                             0\n",
       "Family History of Mental Illness             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a973d8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_professions_test = {\n",
    "    \"Unhealthy\",\"B.Ed\",\"Working Professional\",\"3M\",\"ME\",\"B.Pharm\",\n",
    "    \"24th\",\"Manvi\",\"Yogesh\",\"Samar\",\"Surat\",\"PhD\",\"M.Ed\",\"MD\",\"Name\",\"MCA\",\n",
    "    \"Simran\",\"Analyst\",\"Profession\",\"BBA\",\"M.Tech\",\"LLM\",\"No\",\"Unveil\",\n",
    "    \"City Consultant\",\"M.Pharm\"\n",
    "}\n",
    "\n",
    "df_test['Profession'] = df_test['Profession'].apply(lambda x: \"Unknown\" if x in invalid_professions_test else x)\n",
    "\n",
    "profession_corrections_test = {\n",
    "    \"Finanancial Analyst\": \"Financial Analyst\",\n",
    "    \"Medical Doctor\": \"Doctor\"\n",
    "}\n",
    "\n",
    "df_test['Profession'] = df_test['Profession'].replace(profession_corrections_test)\n",
    "df_test = df_test.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01b0bd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_sleep_test = {\n",
    "    \"0\",\"Meerut\",\"Vivan\",\"Unhealthy\",\"Have_you_ever_had_suicidal_thoughts\",\n",
    "    \"60-65 hours\",\"50-75 hours\",\"9-5\",\"9-5 hours\",\"9-6 hours\",\"10-6 hours\",\"1-6 hours\"\n",
    "}\n",
    "\n",
    "sleep_corrections_test = {\n",
    "    \"than 5 hours\": \"Less than 5 hours\",\n",
    "    \"6 hours\": \"5-6 hours\",\n",
    "    \"8-89 hours\": \"8-9 hours\"\n",
    "}\n",
    "\n",
    "df_test['Sleep Duration'] = df_test['Sleep Duration'].apply(\n",
    "    lambda x: \"Unknown\" if x in invalid_sleep_test or pd.isna(x) else x\n",
    ")\n",
    "\n",
    "df_test['Sleep Duration'] = df_test['Sleep Duration'].replace(sleep_corrections_test)\n",
    "\n",
    "def standardize_sleep_duration_test(val):\n",
    "    if pd.isna(val) or str(val).lower() == \"unknown\":\n",
    "        return \"Unknown\"\n",
    "    val = str(val).strip().lower()\n",
    "    if val in [\"less than 5 hours\", \"1-2 hours\", \"1-3 hours\", \"2-3 hours\",\n",
    "               \"3-4 hours\", \"3-6 hours\", \"4-5 hours\", \"4-6 hours\"]:\n",
    "        return \"<5 hours\"\n",
    "    elif val == \"5-6 hours\":\n",
    "        return \"5-6 hours\"\n",
    "    elif val == \"6-7 hours\":\n",
    "        return \"6-7 hours\"\n",
    "    elif val == \"6-8 hours\":\n",
    "        return \"6-8 hours\"\n",
    "    elif val == \"7-8 hours\":\n",
    "        return \"7-8 hours\"\n",
    "    elif val in [\"8-9 hours\", \"more than 8 hours\"]:\n",
    "        return \"8-9 hours\"\n",
    "    elif val in [\"9-11 hours\", \"9-10 hours\", \"10-11 hours\"]:\n",
    "        return \"9-11 hours\"\n",
    "    else:\n",
    "        return val\n",
    "\n",
    "df_test['Sleep Duration'] = df_test['Sleep Duration'].apply(standardize_sleep_duration_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9c9b4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_diet_test = {\n",
    "    \"No\",\"Indoor\",\"Prachi\",\"Male\",\"Mealy\",\"Resistant\",\"MCA\",\n",
    "    \"Academic\",\"Educational\",\"Soham\",\"Vivaan\",\"Raghav\",\"1.0\",\"Naina\",\"Kolkata\"\n",
    "}\n",
    "\n",
    "diet_corrections_test = {\n",
    "    \"No Healthy\": \"Unhealthy\",\n",
    "    \"Less Healthy\": \"Unhealthy\",\n",
    "    \"More Healthy\": \"Healthy\",\n",
    "    \"Less than Healthy\": \"Unhealthy\",\n",
    "    \"5 Healthy\": \"Healthy\",\n",
    "    \"5 Unhealthy\": \"Unhealthy\"\n",
    "}\n",
    "\n",
    "df_test['Dietary Habits'] = df_test['Dietary Habits'].apply(\n",
    "    lambda x: \"Unknown\" if x in invalid_diet_test or pd.isna(x) else x\n",
    ")\n",
    "\n",
    "df_test['Dietary Habits'] = df_test['Dietary Habits'].replace(diet_corrections_test)\n",
    "df_test = df_test.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a569809e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Moderate', 'Healthy', 'Unhealthy', 'Unknown'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"Dietary Habits\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b4f949a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_test.select_dtypes(include=['object']).columns:\n",
    "    df_test[col] = df_test[col].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05903d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "degree_corrections_test = {\n",
    "    'BEd': 'B.Ed',\n",
    "    'MEd': 'M.Ed',\n",
    "    'MTech': 'M.Tech',\n",
    "    'M_Tech': 'M.Tech',\n",
    "    'BArch': 'B.Arch',\n",
    "    'B BBA': 'BBA',\n",
    "    'B.BA': 'BBA',\n",
    "    'B B.Com': 'B.Com',\n",
    "    'B_Com': 'B.Com',\n",
    "    'BSc': 'B.Sc',\n",
    "    'B.Sc': 'B.Sc',\n",
    "    'MSc': 'M.Sc',\n",
    "    'PhD': 'Ph.D',\n",
    "    'MPharm': 'M.Pharm',\n",
    "    'BPharm': 'B.Pharm',\n",
    "    'B._Pharm': 'B.Pharm',\n",
    "    'LLCom': 'LLB',\n",
    "    'LLBA': 'LLB',\n",
    "    'LL.B': 'LLB',\n",
    "    'BCA': 'B.C.A',\n",
    "    'B.CA': 'B.C.A',\n",
    "    'MCA': 'M.C.A',\n",
    "    'MBA': 'M.B.A',\n",
    "    'BTech': 'B.Tech',\n",
    "    'BE': 'B.E',\n",
    "    'ME': 'M.E',\n",
    "    'MHM': 'M.H.M',\n",
    "    'M.Arch': 'M.Arch',\n",
    "    'A.Ed': 'A.Ed',\n",
    "    'I.Ed': 'I.Ed',\n",
    "    'M.B.Ed': 'M.B.Ed'\n",
    "}\n",
    "\n",
    "df_test['Degree'] = df_test['Degree'].replace(degree_corrections_test)\n",
    "\n",
    "\n",
    "invalid_degrees_test = [\n",
    "    'Advait', 'Vibha', 'Navya', 'Eshita', 'Magan', 'Gagan', 'Rupak', \n",
    "    'Kavya', 'Pune', 'Bhopal', 'Degree', 'Mechanical Engineer',\n",
    "    'Travel Consultant', 'Business Analyst', 'B Financial Analyst',\n",
    "    '5.65', '8.9', '3.0', 'B.H', 'B. Gender', 'B.Study_Hours'\n",
    "]\n",
    "\n",
    "df_test['Degree'] = df_test['Degree'].apply(lambda x: \"Unknown\" if x in invalid_degrees_test else x)\n",
    "\n",
    "\n",
    "df_test['Degree'] = df_test['Degree'].str.replace('.', '', regex=False).str.strip().str.upper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9603ff2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender ['Male' 'Female']\n",
      "City ['Visakhapatnam' 'Kolkata' 'Jaipur' 'Rajkot' 'Kalyan' 'Mumbai' 'Surat'\n",
      " 'Srinagar' 'Delhi' 'Lucknow' 'Thane' 'Meerut' 'Nagpur' 'Ghaziabad'\n",
      " 'Chennai' 'Varanasi' 'Indore' 'Pune' 'Hyderabad' 'Kanpur' 'Nashik'\n",
      " 'Bhopal' 'Faridabad' 'Bangalore' 'Vasai-Virar' 'Ludhiana' 'Patna'\n",
      " 'Vadodara' 'Ahmedabad' 'Agra' 'Unknown']\n",
      "Working Professional or Student ['Working Professional' 'Student']\n",
      "Profession ['Judge' 'Educational Consultant' 'Teacher' nan 'Customer Support'\n",
      " 'Chemist' 'Content Writer' 'Consultant' 'HR Manager' 'Research Analyst'\n",
      " 'Digital Marketer' 'Electrician' 'Marketing Manager' 'Plumber'\n",
      " 'Pharmacist' 'Lawyer' 'Pilot' 'Architect' 'Chef' 'Graphic Designer'\n",
      " 'Entrepreneur' 'Manager' 'Mechanical Engineer' 'Software Engineer'\n",
      " 'Travel Consultant' 'Financial Analyst' 'Doctor' 'Business Analyst'\n",
      " 'UX/UI Designer' 'Sales Executive' 'Data Scientist' 'Accountant'\n",
      " 'Researcher' 'Civil Engineer' 'Investment Banker' 'Unknown' 'Student'\n",
      " 'Unemployed' 'Surgeon']\n",
      "Sleep Duration ['<5 hours' '7-8 hours' '8-9 hours' '5-6 hours' 'Unknown' '6-7 hours'\n",
      " '20-21 hours' '9-11 hours']\n",
      "Dietary Habits ['Moderate' 'Healthy' 'Unhealthy' 'Unknown']\n",
      "Degree ['LLB' 'BED' 'BARCH' 'BSC' 'BCA' 'BCOM' 'MA' 'BA' 'BBA' 'CLASS 12' 'MD'\n",
      " 'MBA' 'MED' 'MPHARM' 'BHM' 'LLM' 'PHD' 'MCOM' 'BE' 'MBBS' 'BTECH' 'ME'\n",
      " 'MCA' 'BPHARM' 'MHM' 'MTECH' 'MSC' 'UNKNOWN' 'MARCH' 'AED' 'B' 'MUI'\n",
      " 'B BCA' 'BPRESS' 'BIAN' 'BMCOM' 'MMED' 'SPHARM' 'VRINDA' 'M' 'EED'\n",
      " 'MOHAM' nan 'IED' 'B BTECH' 'MBED' 'GCA' 'GED' 'RCA' 'PCA' 'JED' 'BH'\n",
      " '895' 'AADHYA' '20' 'BANCHAL' 'KED' 'BHCA']\n",
      "Have you ever had suicidal thoughts ? ['No' 'Yes']\n",
      "Family History of Mental Illness ['Yes' 'No']\n"
     ]
    }
   ],
   "source": [
    "for i in df_test.select_dtypes(include = [\"object\"]).columns:\n",
    "\t\t\t print(i, df_test[i].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926cbdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "invalid_extra_degrees = ['B', 'M', 'VRINDA', 'MOHAM', '895', '20']\n",
    "\n",
    "df_test['Degree'] = df_test['Degree'].apply(lambda x: \"UNKNOWN\" if x in invalid_extra_degrees else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb6eb8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender ['Male' 'Female']\n",
      "City ['Visakhapatnam' 'Kolkata' 'Jaipur' 'Rajkot' 'Kalyan' 'Mumbai' 'Surat'\n",
      " 'Srinagar' 'Delhi' 'Lucknow' 'Thane' 'Meerut' 'Nagpur' 'Ghaziabad'\n",
      " 'Chennai' 'Varanasi' 'Indore' 'Pune' 'Hyderabad' 'Kanpur' 'Nashik'\n",
      " 'Bhopal' 'Faridabad' 'Bangalore' 'Vasai-Virar' 'Ludhiana' 'Patna'\n",
      " 'Vadodara' 'Ahmedabad' 'Agra' 'Unknown']\n",
      "Working Professional or Student ['Working Professional' 'Student']\n",
      "Profession ['Judge' 'Educational Consultant' 'Teacher' nan 'Customer Support'\n",
      " 'Chemist' 'Content Writer' 'Consultant' 'HR Manager' 'Research Analyst'\n",
      " 'Digital Marketer' 'Electrician' 'Marketing Manager' 'Plumber'\n",
      " 'Pharmacist' 'Lawyer' 'Pilot' 'Architect' 'Chef' 'Graphic Designer'\n",
      " 'Entrepreneur' 'Manager' 'Mechanical Engineer' 'Software Engineer'\n",
      " 'Travel Consultant' 'Financial Analyst' 'Doctor' 'Business Analyst'\n",
      " 'UX/UI Designer' 'Sales Executive' 'Data Scientist' 'Accountant'\n",
      " 'Researcher' 'Civil Engineer' 'Investment Banker' 'Unknown' 'Student'\n",
      " 'Unemployed' 'Surgeon']\n",
      "Sleep Duration ['<5 hours' '7-8 hours' '8-9 hours' '5-6 hours' 'Unknown' '6-7 hours'\n",
      " '20-21 hours' '9-11 hours']\n",
      "Dietary Habits ['Moderate' 'Healthy' 'Unhealthy' 'Unknown']\n",
      "Degree ['LLB' 'BED' 'BARCH' 'BSC' 'BCA' 'BCOM' 'MA' 'BA' 'BBA' 'CLASS 12' 'MD'\n",
      " 'MBA' 'MED' 'MPHARM' 'BHM' 'LLM' 'PHD' 'MCOM' 'BE' 'MBBS' 'BTECH' 'ME'\n",
      " 'MCA' 'BPHARM' 'MHM' 'MTECH' 'MSC' 'UNKNOWN' 'MARCH' 'AED' 'MUI' 'B BCA'\n",
      " 'BPRESS' 'BIAN' 'BMCOM' 'MMED' 'SPHARM' 'EED' nan 'IED' 'B BTECH' 'MBED'\n",
      " 'GCA' 'GED' 'RCA' 'PCA' 'JED' 'BH' 'AADHYA' 'BANCHAL' 'KED' 'BHCA']\n",
      "Have you ever had suicidal thoughts ? ['No' 'Yes']\n",
      "Family History of Mental Illness ['Yes' 'No']\n"
     ]
    }
   ],
   "source": [
    "for i in df_test.select_dtypes(include = [\"object\"]).columns:\n",
    "\t\t\t print(i, df_test[i].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8507da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "invalid_entries = ['B', 'M', 'VRINDA', 'MOHAM', '895', '20', 'BIAN', 'AADHYA', 'BANCHAL']\n",
    "\n",
    "df_test['Degree'] = df_test['Degree'].apply(lambda x: \"UNKNOWN\" if x in invalid_entries else x)\n",
    "\n",
    "df_test['Degree'] = df_test['Degree'].str.replace('.', '', regex=False).str.strip().str.upper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45492e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender ['Male' 'Female']\n",
      "City ['Visakhapatnam' 'Kolkata' 'Jaipur' 'Rajkot' 'Kalyan' 'Mumbai' 'Surat'\n",
      " 'Srinagar' 'Delhi' 'Lucknow' 'Thane' 'Meerut' 'Nagpur' 'Ghaziabad'\n",
      " 'Chennai' 'Varanasi' 'Indore' 'Pune' 'Hyderabad' 'Kanpur' 'Nashik'\n",
      " 'Bhopal' 'Faridabad' 'Bangalore' 'Vasai-Virar' 'Ludhiana' 'Patna'\n",
      " 'Vadodara' 'Ahmedabad' 'Agra' 'Unknown']\n",
      "Working Professional or Student ['Working Professional' 'Student']\n",
      "Profession ['Judge' 'Educational Consultant' 'Teacher' nan 'Customer Support'\n",
      " 'Chemist' 'Content Writer' 'Consultant' 'HR Manager' 'Research Analyst'\n",
      " 'Digital Marketer' 'Electrician' 'Marketing Manager' 'Plumber'\n",
      " 'Pharmacist' 'Lawyer' 'Pilot' 'Architect' 'Chef' 'Graphic Designer'\n",
      " 'Entrepreneur' 'Manager' 'Mechanical Engineer' 'Software Engineer'\n",
      " 'Travel Consultant' 'Financial Analyst' 'Doctor' 'Business Analyst'\n",
      " 'UX/UI Designer' 'Sales Executive' 'Data Scientist' 'Accountant'\n",
      " 'Researcher' 'Civil Engineer' 'Investment Banker' 'Unknown' 'Student'\n",
      " 'Unemployed' 'Surgeon']\n",
      "Sleep Duration ['<5 hours' '7-8 hours' '8-9 hours' '5-6 hours' 'Unknown' '6-7 hours'\n",
      " '20-21 hours' '9-11 hours']\n",
      "Dietary Habits ['Moderate' 'Healthy' 'Unhealthy' 'Unknown']\n",
      "Degree ['LLB' 'BED' 'BARCH' 'BSC' 'BCA' 'BCOM' 'MA' 'BA' 'BBA' 'CLASS 12' 'MD'\n",
      " 'MBA' 'MED' 'MPHARM' 'BHM' 'LLM' 'PHD' 'MCOM' 'BE' 'MBBS' 'BTECH' 'ME'\n",
      " 'MCA' 'BPHARM' 'MHM' 'MTECH' 'MSC' 'UNKNOWN' 'MARCH' 'AED' 'MUI' 'B BCA'\n",
      " 'BPRESS' 'BMCOM' 'MMED' 'SPHARM' 'EED' nan 'IED' 'B BTECH' 'MBED' 'GCA'\n",
      " 'GED' 'RCA' 'PCA' 'JED' 'BH' 'KED' 'BHCA']\n",
      "Have you ever had suicidal thoughts ? ['No' 'Yes']\n",
      "Family History of Mental Illness ['Yes' 'No']\n"
     ]
    }
   ],
   "source": [
    "for i in df_test.select_dtypes(include = [\"object\"]).columns:\n",
    "\t\t\t print(i, df_test[i].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc72a5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "degree_corrections_test = {\n",
    "    'BEd': 'B.Ed',\n",
    "    'MEd': 'M.Ed',\n",
    "    'MTech': 'M.Tech',\n",
    "    'M_Tech': 'M.Tech',\n",
    "    'BArch': 'B.Arch',\n",
    "    'B.BA': 'BBA',\n",
    "    'B BBA': 'BBA',\n",
    "    'B B.Com': 'B.Com',\n",
    "    'B_Com': 'B.Com',\n",
    "    'BSc': 'B.Sc',\n",
    "    'B.Sc': 'B.Sc',\n",
    "    'MSc': 'M.Sc',\n",
    "    'PhD': 'Ph.D',\n",
    "    'MPharm': 'M.Pharm',\n",
    "    'BPharm': 'B.Pharm',\n",
    "    'B._Pharm': 'B.Pharm',\n",
    "    'LLCom': 'LLB',\n",
    "    'LLBA': 'LLB',\n",
    "    'LL.B': 'LLB',\n",
    "    'BCA': 'B.C.A',\n",
    "    'B.CA': 'B.C.A',\n",
    "    'MCA': 'M.C.A',\n",
    "    'MBA': 'M.B.A',\n",
    "    'BTech': 'B.Tech',\n",
    "    'BE': 'B.E',\n",
    "    'ME': 'M.E',\n",
    "    'MHM': 'M.H.M',\n",
    "    'M.Arch': 'M.Arch',\n",
    "    'A.Ed': 'A.Ed',\n",
    "    'I.Ed': 'I.Ed',\n",
    "    'M.B.Ed': 'M.B.Ed'\n",
    "    \n",
    "}\n",
    "\n",
    "df_test['Degree'] = df_test['Degree'].replace(degree_corrections_test)\n",
    "\n",
    "\n",
    "degree_mapping = {\n",
    "    'B BTECH': 'BTECH',\n",
    "    'B BCA': 'BCA',\n",
    "    'G.Ed': 'GED'\n",
    "}\n",
    "\n",
    "df_test['Degree'] = df_test['Degree'].replace(degree_mapping)\n",
    "\n",
    "invalid_degrees_final = [\n",
    "    'BPRESS', 'BMCOM', 'MMED', 'SPHARM', 'EED', 'AED', 'IED',\n",
    "    'RCA', 'PCA', 'JED', 'BH', 'KED', 'B', 'M', 'MUI',\n",
    "    'VRINDA', 'MOHAM', 'BIAN', 'AADHYA', 'BANCHAL', '20', '895'\n",
    "]\n",
    "\n",
    "df_test['Degree'] = df_test['Degree'].apply(lambda x: \"UNKNOWN\" if x in invalid_degrees_final else x)\n",
    "\n",
    "df_test['Degree'] = df_test['Degree'].str.replace('.', '', regex=False).str.strip().str.upper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6279e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LLB', 'BED', 'BARCH', 'BSC', 'BCA', 'BCOM', 'MA', 'BA', 'BBA',\n",
       "       'CLASS 12', 'MD', 'MBA', 'MED', 'MPHARM', 'BHM', 'LLM', 'PHD',\n",
       "       'MCOM', 'BE', 'MBBS', 'BTECH', 'ME', 'MCA', 'BPHARM', 'MHM',\n",
       "       'MTECH', 'MSC', 'UNKNOWN', 'MARCH', nan, 'MBED', 'GCA', 'GED',\n",
       "       'BHCA'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"Degree\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52a66a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93800, 18)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c937ab5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                           0\n",
       "Gender                                       0\n",
       "Age                                          0\n",
       "City                                         0\n",
       "Working Professional or Student              0\n",
       "Profession                               24632\n",
       "Academic Pressure                        75033\n",
       "Work Pressure                            18778\n",
       "CGPA                                     75034\n",
       "Study Satisfaction                       75033\n",
       "Job Satisfaction                         18774\n",
       "Sleep Duration                               0\n",
       "Dietary Habits                               0\n",
       "Degree                                       2\n",
       "Have you ever had suicidal thoughts ?        0\n",
       "Work/Study Hours                             0\n",
       "Financial Stress                             0\n",
       "Family History of Mental Illness             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ce856c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of working professionals with NaN in Profession: 5886\n"
     ]
    }
   ],
   "source": [
    "nan_prof_working_professionals = df_test[(df_test['Working Professional or Student'] == 'Working Professional') & (df_test['Profession'].isna())]\n",
    "\n",
    "\n",
    "count_nan_prof_working = nan_prof_working_professionals.shape[0]\n",
    "\n",
    "print(f\"Number of working professionals with NaN in Profession: {count_nan_prof_working}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8eaf542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_student = (df_test['Working Professional or Student'] == 'Student') & (df_test['Profession'].isna())\n",
    "df_test.loc[mask_student, 'Profession'] = 'Student'\n",
    "\n",
    "mask_working = (df_test['Working Professional or Student'] == 'Working Professional') & (df_test['Profession'].isna())\n",
    "df_test.loc[mask_working, 'Profession'] = 'Unknown'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59d6bb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Professional or Student\n",
      "Student                     7\n",
      "Working Professional    75026\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_academic_pressure_counts = df_test[df_test['Academic Pressure'].isna()].groupby('Working Professional or Student').size()\n",
    "\n",
    "print(nan_academic_pressure_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df7552f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_student_pressure = df_test.loc[df_test['Working Professional or Student'] == 'Student', 'Academic Pressure'].median()\n",
    "\n",
    "mask_student_nan = (df_test['Working Professional or Student'] == 'Student') & (df_test['Academic Pressure'].isna())\n",
    "df_test.loc[mask_student_nan, 'Academic Pressure'] = median_student_pressure\n",
    "\n",
    "mask_working_nan = (df_test['Working Professional or Student'] == 'Working Professional') & (df_test['Academic Pressure'].isna())\n",
    "df_test.loc[mask_working_nan, 'Academic Pressure'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96dbfa02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of working professionals with NaN in Work Pressure: 10\n"
     ]
    }
   ],
   "source": [
    "nan_work_pressure_working = df_test[(df_test['Work Pressure'].isna()) & (df_test['Working Professional or Student'] == 'Working Professional')]\n",
    "\n",
    "count_nan_work_pressure_working = nan_work_pressure_working.shape[0]\n",
    "\n",
    "print(f\"Number of working professionals with NaN in Work Pressure: {count_nan_work_pressure_working}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14a3d18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_work_pressure = df_test.loc[df_test['Working Professional or Student'] == 'Working Professional', 'Work Pressure'].median()\n",
    "\n",
    "mask_nan_working = (df_test['Working Professional or Student'] == 'Working Professional') & (df_test['Work Pressure'].isna())\n",
    "df_test.loc[mask_nan_working, 'Work Pressure'] = median_work_pressure\n",
    "\n",
    "mask_nan_students = (df_test['Working Professional or Student'] == 'Student') & (df_test['Work Pressure'].isna())\n",
    "df_test.loc[mask_nan_students, 'Work Pressure'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1861b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Professional or Student\n",
      "Student                     9\n",
      "Working Professional    75025\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_cgpa_counts = df_test[df_test['CGPA'].isna()].groupby('Working Professional or Student').size()\n",
    "\n",
    "print(nan_cgpa_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7c8271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_cgpa_students = df_test.loc[df_test['Working Professional or Student'] == 'Student', 'CGPA'].median()\n",
    "\n",
    "mask_student_cgpa_nan = (df_test['Working Professional or Student'] == 'Student') & (df_test['CGPA'].isna())\n",
    "df_test.loc[mask_student_cgpa_nan, 'CGPA'] = median_cgpa_students\n",
    "\n",
    "mask_working_cgpa_nan = (df_test['Working Professional or Student'] == 'Working Professional') & (df_test['CGPA'].isna())\n",
    "df_test.loc[mask_working_cgpa_nan, 'CGPA'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f0a5943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Professional or Student\n",
      "Student                     8\n",
      "Working Professional    75025\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_study_satisfaction_counts = df_test[df_test['Study Satisfaction'].isna()].groupby('Working Professional or Student').size()\n",
    "\n",
    "print(nan_study_satisfaction_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ffc7ebfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_study_satisfaction_students = df_test.loc[df_test['Working Professional or Student'] == 'Student', 'Study Satisfaction'].median()\n",
    "\n",
    "mask_student_study_nan = (df_test['Working Professional or Student'] == 'Student') & (df_test['Study Satisfaction'].isna())\n",
    "df_test.loc[mask_student_study_nan, 'Study Satisfaction'] = median_study_satisfaction_students\n",
    "\n",
    "mask_working_study_nan = (df_test['Working Professional or Student'] == 'Working Professional') & (df_test['Study Satisfaction'].isna())\n",
    "df_test.loc[mask_working_study_nan, 'Study Satisfaction'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7dae199a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Professional or Student\n",
      "Student                 18765\n",
      "Working Professional        9\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_job_satisfaction_counts = df_test[df_test['Job Satisfaction'].isna()].groupby('Working Professional or Student').size()\n",
    "\n",
    "print(nan_job_satisfaction_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa8e63fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_job_satisfaction_working = df_test.loc[df_test['Working Professional or Student'] == 'Working Professional', 'Job Satisfaction'].median()\n",
    "\n",
    "mask_working_job_nan = (df_test['Working Professional or Student'] == 'Working Professional') & (df_test['Job Satisfaction'].isna())\n",
    "df_test.loc[mask_working_job_nan, 'Job Satisfaction'] = median_job_satisfaction_working\n",
    "\n",
    "mask_student_job_nan = (df_test['Working Professional or Student'] == 'Student') & (df_test['Job Satisfaction'].isna())\n",
    "df_test.loc[mask_student_job_nan, 'Job Satisfaction'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ee91700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prakash Kumar\\AppData\\Local\\Temp\\ipykernel_2432\\3835160965.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_test['Degree'].fillna(mode_degree, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "mode_degree = df_test['Degree'].mode()[0]\n",
    "df_test['Degree'].fillna(mode_degree, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef41ecbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                       0\n",
       "Gender                                   0\n",
       "Age                                      0\n",
       "City                                     0\n",
       "Working Professional or Student          0\n",
       "Profession                               0\n",
       "Academic Pressure                        0\n",
       "Work Pressure                            0\n",
       "CGPA                                     0\n",
       "Study Satisfaction                       0\n",
       "Job Satisfaction                         0\n",
       "Sleep Duration                           0\n",
       "Dietary Habits                           0\n",
       "Degree                                   0\n",
       "Have you ever had suicidal thoughts ?    0\n",
       "Work/Study Hours                         0\n",
       "Financial Stress                         0\n",
       "Family History of Mental Illness         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e704b552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93800, 18)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9f523e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d2a5ce9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_test = df_test.drop(columns=['id'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a52c686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93800, 17)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a4b62ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\n",
    "    'Gender', \n",
    "    'City', \n",
    "    'Working Professional or Student', \n",
    "    'Profession', \n",
    "    'Dietary Habits', \n",
    "    'Degree', \n",
    "    'Have you ever had suicidal thoughts ?',\n",
    "    'Family History of Mental Illness',\n",
    "    'Sleep Duration'\n",
    "]\n",
    "\n",
    "df_test_encoded = pd.get_dummies(df_test, columns=categorical_cols, drop_first=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cec6a6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93800, 130)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "332fcc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_test_encoded.to_csv('encoded_test_new.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "34e10925",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = [\n",
    "    'Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction',\n",
    "    'Job Satisfaction', 'Work/Study Hours', 'Financial Stress'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8d9e3281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers in Age: 0\n",
      "Outliers in Academic Pressure: 4321\n",
      "Outliers in Work Pressure: 0\n",
      "Outliers in CGPA: 0\n",
      "Outliers in Study Satisfaction: 3069\n",
      "Outliers in Job Satisfaction: 0\n",
      "Outliers in Work/Study Hours: 0\n",
      "Outliers in Financial Stress: 0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "outliers = {}\n",
    "for col in numerical_cols:\n",
    "    z_scores = zscore(df_test_encoded[col])\n",
    "    outliers[col] = (abs(z_scores) > 3).sum()\n",
    "    print(f'Outliers in {col}: {outliers[col]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5fa2c5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Skewness  Kurtosis\n",
      "Age                -0.206914 -1.154562\n",
      "Academic Pressure   2.099458  2.989018\n",
      "Work Pressure       0.047196 -1.293984\n",
      "CGPA                1.655629  0.971539\n",
      "Study Satisfaction  2.187599  3.475257\n",
      "Job Satisfaction    0.095337 -1.270466\n",
      "Work/Study Hours   -0.126205 -1.283987\n",
      "Financial Stress    0.045516 -1.315578\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import skew, kurtosis\n",
    "skewness_values = df_test_encoded[numerical_cols].apply(lambda x: skew(x, bias=False))\n",
    "\n",
    "kurtosis_values = df_test_encoded[numerical_cols].apply(lambda x: kurtosis(x, fisher=True, bias=False))\n",
    "\n",
    "\n",
    "stats_df = pd.DataFrame({\n",
    "    'Skewness': skewness_values,\n",
    "    'Kurtosis': kurtosis_values\n",
    "})\n",
    "\n",
    "print(stats_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "95cfdc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_transform = ['Academic Pressure', 'CGPA', 'Study Satisfaction']\n",
    "\n",
    "for col in cols_to_transform:\n",
    "    df_test_encoded[col] = np.log1p(df_test_encoded[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2d3a349d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers in Age: 0\n",
      "Outliers in Academic Pressure: 0\n",
      "Outliers in Work Pressure: 0\n",
      "Outliers in CGPA: 0\n",
      "Outliers in Study Satisfaction: 0\n",
      "Outliers in Job Satisfaction: 0\n",
      "Outliers in Work/Study Hours: 0\n",
      "Outliers in Financial Stress: 0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "outliers = {}\n",
    "for col in numerical_cols:\n",
    "    z_scores = zscore(df_test_encoded[col])\n",
    "    outliers[col] = (abs(z_scores) > 3).sum()\n",
    "    print(f'Outliers in {col}: {outliers[col]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e964cd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Skewness  Kurtosis\n",
      "Age                -0.206914 -1.154562\n",
      "Academic Pressure   1.772271  1.430487\n",
      "Work Pressure       0.047196 -1.293984\n",
      "CGPA                1.528585  0.383816\n",
      "Study Satisfaction  1.810977  1.626945\n",
      "Job Satisfaction    0.095337 -1.270466\n",
      "Work/Study Hours   -0.126205 -1.283987\n",
      "Financial Stress    0.045516 -1.315578\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import skew, kurtosis\n",
    "skewness_values = df_test_encoded[numerical_cols].apply(lambda x: skew(x, bias=False))\n",
    "\n",
    "kurtosis_values = df_test_encoded[numerical_cols].apply(lambda x: kurtosis(x, fisher=True, bias=False))\n",
    "\n",
    "\n",
    "stats_df = pd.DataFrame({\n",
    "    'Skewness': skewness_values,\n",
    "    'Kurtosis': kurtosis_values\n",
    "})\n",
    "\n",
    "print(stats_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "89c931a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_test_encoded.to_csv('final_test_new.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "edef7392",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_final = pd.read_csv(r\"D:\\GUVI\\Mental_health_survey\\env\\final_test_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "87854396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93800, 130)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3812b0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Columns in train: 135\n",
      "✅ Columns in test : 130\n",
      "\n",
      "🔍 Missing in test (need to add): {'Degree_CLASS 11', 'Degree_RCA', 'Degree_LED', 'Profession_Family Consultant', 'Degree_BBARCH', 'City_Morena', 'Sleep Duration_6-8 hours', 'City_Gurgaon', 'Degree_MPA', 'Degree_PPHARM', 'Profession_Analyst'}\n",
      "🔍 Extra in test (not in train): {'Sleep Duration_20-21 hours', 'Degree_GCA', 'Degree_MBED', 'Profession_Surgeon', 'Degree_GED', 'Degree_BHCA'}\n"
     ]
    }
   ],
   "source": [
    "def check_column_alignment(train_df, test_df):\n",
    "    train_cols = set(train_df.columns)\n",
    "    test_cols = set(test_df.columns)\n",
    "\n",
    "    missing_in_test = train_cols - test_cols\n",
    "    extra_in_test = test_cols - train_cols\n",
    "\n",
    "    print(\"✅ Columns in train:\", len(train_cols))\n",
    "    print(\"✅ Columns in test :\", len(test_cols))\n",
    "    print(\"\\n🔍 Missing in test (need to add):\", missing_in_test if missing_in_test else \"None\")\n",
    "    print(\"🔍 Extra in test (not in train):\", extra_in_test if extra_in_test else \"None\")\n",
    "\n",
    "\n",
    "X = df_train_final.drop(columns=['Depression'])\n",
    "y = df_train_final['Depression']\n",
    "\n",
    "check_column_alignment(X, df_test_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da06b7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_final = df_test_final.reindex(columns=X.columns, fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d27264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Columns in train: 135\n",
      "✅ Columns in test : 135\n",
      "\n",
      "🔍 Missing in test (need to add): None\n",
      "🔍 Extra in test (not in train): None\n"
     ]
    }
   ],
   "source": [
    "def check_column_alignment(train_df, test_df):\n",
    "    train_cols = set(train_df.columns)\n",
    "    test_cols = set(test_df.columns)\n",
    "\n",
    "    missing_in_test = train_cols - test_cols\n",
    "    extra_in_test = test_cols - train_cols\n",
    "\n",
    "    print(\"✅ Columns in train:\", len(train_cols))\n",
    "    print(\"✅ Columns in test :\", len(test_cols))\n",
    "    print(\"\\n🔍 Missing in test (need to add):\", missing_in_test if missing_in_test else \"None\")\n",
    "    print(\"🔍 Extra in test (not in train):\", extra_in_test if extra_in_test else \"None\")\n",
    "\n",
    "\n",
    "X = df_train_final.drop(columns=['Depression'])\n",
    "y = df_train_final['Depression']\n",
    "\n",
    "check_column_alignment(X, df_test_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b7188796",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "scaler = load(\"scaler.save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0f273d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = scaler.transform(df_test_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f084c4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "model = keras.models.load_model('mental_health_survey_final.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "778741dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2932/2932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 738us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = model.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f707c41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred_test_classes = (y_pred_test > 0.5).astype(int).flatten()\n",
    "\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'Depression': y_pred_test_classes\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da384528",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

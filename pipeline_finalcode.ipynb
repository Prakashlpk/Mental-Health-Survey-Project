{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e2a6132",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prakash Kumar\\AppData\\Local\\Temp\\ipykernel_23200\\259147784.py:211: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Financial Stress'].fillna(df['Financial Stress'].median(), inplace=True)\n",
      "d:\\GUVI\\Mental_health_survey\\env\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8677 - auc: 0.9101 - loss: 0.3714 - precision: 0.6030 - recall: 0.7960 - val_accuracy: 0.9328 - val_auc: 0.9595 - val_loss: 0.2171 - val_precision: 0.8534 - val_recall: 0.7608\n",
      "Epoch 2/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9293 - auc: 0.9572 - loss: 0.2064 - precision: 0.8223 - recall: 0.7794 - val_accuracy: 0.9348 - val_auc: 0.9692 - val_loss: 0.1778 - val_precision: 0.8183 - val_recall: 0.8244\n",
      "Epoch 3/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9331 - auc: 0.9665 - loss: 0.1754 - precision: 0.8292 - recall: 0.7956 - val_accuracy: 0.9370 - val_auc: 0.9714 - val_loss: 0.1606 - val_precision: 0.8367 - val_recall: 0.8115\n",
      "Epoch 4/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9345 - auc: 0.9688 - loss: 0.1679 - precision: 0.8342 - recall: 0.7981 - val_accuracy: 0.9368 - val_auc: 0.9720 - val_loss: 0.1598 - val_precision: 0.8353 - val_recall: 0.8124\n",
      "Epoch 5/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9353 - auc: 0.9707 - loss: 0.1633 - precision: 0.8358 - recall: 0.8013 - val_accuracy: 0.9373 - val_auc: 0.9726 - val_loss: 0.1581 - val_precision: 0.8340 - val_recall: 0.8177\n",
      "Epoch 6/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9372 - auc: 0.9719 - loss: 0.1601 - precision: 0.8395 - recall: 0.8089 - val_accuracy: 0.9370 - val_auc: 0.9719 - val_loss: 0.1588 - val_precision: 0.8335 - val_recall: 0.8165\n",
      "Epoch 7/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9374 - auc: 0.9730 - loss: 0.1578 - precision: 0.8394 - recall: 0.8106 - val_accuracy: 0.9360 - val_auc: 0.9716 - val_loss: 0.1589 - val_precision: 0.8272 - val_recall: 0.8191\n",
      "Epoch 8/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9377 - auc: 0.9733 - loss: 0.1561 - precision: 0.8394 - recall: 0.8127 - val_accuracy: 0.9367 - val_auc: 0.9715 - val_loss: 0.1576 - val_precision: 0.8334 - val_recall: 0.8142\n",
      "Epoch 9/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9381 - auc: 0.9740 - loss: 0.1545 - precision: 0.8410 - recall: 0.8131 - val_accuracy: 0.9378 - val_auc: 0.9716 - val_loss: 0.1574 - val_precision: 0.8302 - val_recall: 0.8269\n",
      "Epoch 10/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9396 - auc: 0.9747 - loss: 0.1525 - precision: 0.8423 - recall: 0.8216 - val_accuracy: 0.9365 - val_auc: 0.9714 - val_loss: 0.1578 - val_precision: 0.8374 - val_recall: 0.8075\n",
      "Epoch 11/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9391 - auc: 0.9744 - loss: 0.1522 - precision: 0.8433 - recall: 0.8169 - val_accuracy: 0.9371 - val_auc: 0.9714 - val_loss: 0.1579 - val_precision: 0.8354 - val_recall: 0.8142\n",
      "Epoch 12/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9393 - auc: 0.9750 - loss: 0.1505 - precision: 0.8425 - recall: 0.8188 - val_accuracy: 0.9373 - val_auc: 0.9715 - val_loss: 0.1576 - val_precision: 0.8382 - val_recall: 0.8119\n",
      "Epoch 13/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9399 - auc: 0.9754 - loss: 0.1498 - precision: 0.8453 - recall: 0.8190 - val_accuracy: 0.9367 - val_auc: 0.9715 - val_loss: 0.1579 - val_precision: 0.8484 - val_recall: 0.7933\n",
      "Epoch 14/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9403 - auc: 0.9759 - loss: 0.1479 - precision: 0.8458 - recall: 0.8210 - val_accuracy: 0.9366 - val_auc: 0.9713 - val_loss: 0.1585 - val_precision: 0.8409 - val_recall: 0.8032\n",
      "Epoch 15/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9400 - auc: 0.9762 - loss: 0.1474 - precision: 0.8453 - recall: 0.8200 - val_accuracy: 0.9366 - val_auc: 0.9701 - val_loss: 0.1604 - val_precision: 0.8318 - val_recall: 0.8162\n",
      "Epoch 16/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9410 - auc: 0.9769 - loss: 0.1455 - precision: 0.8456 - recall: 0.8260 - val_accuracy: 0.9375 - val_auc: 0.9707 - val_loss: 0.1587 - val_precision: 0.8445 - val_recall: 0.8040\n",
      "Epoch 17/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9409 - auc: 0.9767 - loss: 0.1454 - precision: 0.8448 - recall: 0.8268 - val_accuracy: 0.9360 - val_auc: 0.9703 - val_loss: 0.1593 - val_precision: 0.8399 - val_recall: 0.8003\n",
      "Epoch 18/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9406 - auc: 0.9772 - loss: 0.1444 - precision: 0.8443 - recall: 0.8253 - val_accuracy: 0.9371 - val_auc: 0.9704 - val_loss: 0.1593 - val_precision: 0.8457 - val_recall: 0.7999\n",
      "Epoch 19/50\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9412 - auc: 0.9770 - loss: 0.1441 - precision: 0.8458 - recall: 0.8269 - val_accuracy: 0.9367 - val_auc: 0.9705 - val_loss: 0.1599 - val_precision: 0.8393 - val_recall: 0.8058\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "\u001b[1m880/880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "Validation Accuracy: 0.9378109452736318\n",
      "Validation Precision: 0.8301590418221088\n",
      "Validation Recall: 0.8269117934676316\n",
      "Validation F1 Score: 0.8285322359396433\n",
      "Validation Confusion Matrix:\n",
      " [[22162   865]\n",
      " [  885  4228]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96     23027\n",
      "           1       0.83      0.83      0.83      5113\n",
      "\n",
      "    accuracy                           0.94     28140\n",
      "   macro avg       0.90      0.89      0.90     28140\n",
      "weighted avg       0.94      0.94      0.94     28140\n",
      "\n",
      "\u001b[1m2932/2932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "# Data cleaning, mapping, and correction\n",
    "# ---------------------------------------\n",
    "\n",
    "def clean_df(df, is_train=True):\n",
    "    # Drop Name if present\n",
    "    if \"Name\" in df.columns:\n",
    "        df = df.drop(columns=[\"Name\"])\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "    # CITY CORRECTIONS\n",
    "    invalid_cities = set([\n",
    "        \"Ishanabad\",\"Vidhi\",\"Ayush\",\"Krishna\",\"Aishwarya\",\"Keshav\",\"Harsha\",\"Nalini\",\"Aditya\",\"Malyansh\",\n",
    "        \"Raghavendra\",\"Saanvi\",\"Bhavna\",\"Nandini\",\"Atharv\",\"Pratyush\",\"Mira\",\"Mihir\",\"Vidya\",\"Anvi\",\n",
    "        \"Krinda\",\"Ayansh\",\"Shrey\",\"Ivaan\",\"Vaanya\",\"Gaurav\",\"Harsh\",\"Reyansh\",\"Kashish\",\"Kibara\",\n",
    "        \"Vaishnavi\",\"Chhavi\",\"Parth\",\"Mahi\",\"Tushar\",\"Rashi\",\"Armaan\",\"Aaradhya\",\"Pooja\",\"Khushi\",\n",
    "        \"Jhanvi\",\"M.Tech\",\"M.Com\",\"MCA\",\"MSc\",\"ME\",\"City\",\"3.0\",\"No\",\"Less Delhi\",\"Less than 5 Kalyan\",\n",
    "        \"Moreadhyay\",\"Researcher\",\"Kagan\",\"Ithal\",\"Galesabad\",\"Itheg\",\"Unirar\",\n",
    "        \"Plata\", \"Ishkarsh\", \"Kashk\", \"Dhruv\"\n",
    "    ])\n",
    "    city_corrections = {\n",
    "        \"Tolkata\": \"Kolkata\",\n",
    "        \"Molkata\": \"Kolkata\",\n",
    "        \"Khaziabad\": \"Ghaziabad\",\n",
    "        \"Nalyan\": \"Kalyan\"\n",
    "    }\n",
    "    if 'City' in df:\n",
    "        df['City'] = df['City'].apply(lambda x: \"Unknown\" if x in invalid_cities else x)\n",
    "        df['City'] = df['City'].replace(city_corrections)\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "    # PROFESSION CORRECTIONS\n",
    "    invalid_professions = [\n",
    "        \"B.Com\", \"BE\", \"MBA\", \"LLM\", \"BCA\", \"BBA\", \"MBBS\", \"B.Ed\", \"M.Ed\", \"PhD\",\n",
    "        \"Student\", \"Working Professional\", \"Academic\", \"Profession\",\n",
    "        \"Yogesh\", \"Dev\", \"Pranav\", \"Yuvraj\",\n",
    "        \"FamilyVirar\", \"City Manager\", \"Patna\", \"Nagpur\",\n",
    "        \"Unveil\", \"Moderate\",\n",
    "        \"Visakhapatnam\"\n",
    "    ]\n",
    "    profession_corrections = {\n",
    "        \"Finanancial Analyst\": \"Financial Analyst\",\n",
    "        \"Medical Doctor\": \"Doctor\"\n",
    "    }\n",
    "    if 'Profession' in df:\n",
    "        df['Profession'] = df['Profession'].apply(lambda x: \"Unknown\" if x in invalid_professions else x)\n",
    "        df['Profession'] = df['Profession'].replace(profession_corrections)\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "    # SLEEP DURATION\n",
    "    invalid_sleep = set([\n",
    "        'Sleep_Duration', 'Indore', 'Pune', 'Moderate', 'Unhealthy', 'No',\n",
    "        'Work_Study_Hours', '45', '49 hours', '35-36 hours', '55-66 hours',\n",
    "        '9-6 hours', '10-6 hours', '9-5', '9-5 hours',\n",
    "        '40-45 hours', '45-48 hours', '1-6 hours'\n",
    "    ])\n",
    "    sleep_corrections = {\n",
    "        'than 5 hours': 'Less than 5 hours',\n",
    "        '8 hours': '7-8 hours'\n",
    "    }\n",
    "    def standardize_sleep_duration(val):\n",
    "        if pd.isna(val) or str(val).lower() == 'unknown':\n",
    "            return 'Unknown'\n",
    "        val = str(val).strip().lower()\n",
    "        if val in ['less than 5 hours', '1-2 hours', '1-3 hours', '2-3 hours',\n",
    "                   '3-4 hours', '3-6 hours', '4-5 hours', '4-6 hours']:\n",
    "            return '<5 hours'\n",
    "        elif val == '5-6 hours':\n",
    "            return '5-6 hours'\n",
    "        elif val == '6-7 hours':\n",
    "            return '6-7 hours'\n",
    "        elif val == '6-8 hours':\n",
    "            return '6-8 hours'\n",
    "        elif val == '7-8 hours':\n",
    "            return '7-8 hours'\n",
    "        elif val in ['8-9 hours', 'more than 8 hours']:\n",
    "            return '8-9 hours'\n",
    "        elif val in ['9-11 hours', '10-11 hours']:\n",
    "            return '9-11 hours'\n",
    "        else:\n",
    "            return val\n",
    "    if 'Sleep Duration' in df:\n",
    "        df['Sleep Duration'] = df['Sleep Duration'].apply(\n",
    "            lambda x: 'Unknown' if x in invalid_sleep or pd.isna(x) else x\n",
    "        )\n",
    "        df['Sleep Duration'] = df['Sleep Duration'].replace(sleep_corrections)\n",
    "        df['Sleep Duration'] = df['Sleep Duration'].apply(standardize_sleep_duration)\n",
    "\n",
    "    # DIETARY HABITS\n",
    "    diet_corrections = {\n",
    "        \"No Healthy\": \"Unhealthy\",\n",
    "        \"Less Healthy\": \"Unhealthy\",\n",
    "        \"More Healthy\": \"Healthy\",\n",
    "        \"Less than Healthy\": \"Unhealthy\"\n",
    "    }\n",
    "    invalid_diet = [\n",
    "        \"Yes\", \"No\", \"Pratham\", \"Mihir\", \"BSc\", \"M.Tech\", \"Class 12\",\n",
    "        \"Gender\", \"Male\", \"3\", \"1.0\", \"2\", \"Hormonal\", \"Electrician\",\n",
    "        \"Vegas\", \"Indoor\"\n",
    "    ]\n",
    "    if 'Dietary Habits' in df:\n",
    "        df['Dietary Habits'] = df['Dietary Habits'].apply(\n",
    "            lambda x: \"Unknown\" if x in invalid_diet else x\n",
    "        )\n",
    "        df['Dietary Habits'] = df['Dietary Habits'].replace(diet_corrections)\n",
    "\n",
    "    # DEGREE\n",
    "    degree_corrections = {\n",
    "        'BEd': 'B.Ed',\n",
    "        'MEd': 'M.Ed',\n",
    "        'MTech': 'M.Tech',\n",
    "        'M_Tech': 'M.Tech',\n",
    "        'BArch': 'B.Arch',\n",
    "        'B BA': 'BBA',\n",
    "        'B B.Com': 'B.Com',\n",
    "        'BSc': 'B.Sc',\n",
    "        'MSc': 'M.Sc',\n",
    "        'PhD': 'Ph.D',\n",
    "        'MPharm': 'M.Pharm',\n",
    "        'BPharm': 'B.Pharm',\n",
    "        'LLCom': 'LL.Com',\n",
    "        'LLBA': 'LL.B',\n",
    "        'BCA': 'B.C.A',\n",
    "        'MCA': 'M.C.A',\n",
    "        'MBA': 'M.B.A'\n",
    "    }\n",
    "    invalid_degrees = [\n",
    "        'Nalini','Veda','Bhopal','Degree','20','H_Pharm','M','P.Com',\n",
    "        'Business Analyst','Data Scientist','Unite','HR Manager','Badhya',\n",
    "        'S.Pharm','Vrinda','M. Business Analyst','Bhavesh','0','29','Vivaan',\n",
    "        'BPA','Plumber','5.61','Brit','B.03','Ritik','5.56','B','7.06','ACA',\n",
    "        'Brithika','CGPA','24','Pihu','BB','Jhanvi','Entrepreneur','8.56',\n",
    "        'LHM','Lata','S.Arch','Marsh','HCA','5.88','B.Student','LL B.Ed',\n",
    "        'M.S','Navya','Mahika','Mthanya','Working Professional','Esha',\n",
    "        'LLS','LLEd','E.Tech','Doctor','N.Pharm','LCA','Mihir','Advait',\n",
    "        'UX/UI Designer', 'BH', 'S.Tech', 'Kalyan', \n",
    "        'LLTech', 'Aarav', 'B.3.79', 'LL.Com', 'K.Ed'\n",
    "    ]\n",
    "    if 'Degree' in df:\n",
    "        df['Degree'] = df['Degree'].replace(degree_corrections)\n",
    "        df['Degree'] = df['Degree'].apply(lambda x: \"Unknown\" if x in invalid_degrees else x)\n",
    "        df['Degree'] = df['Degree'].replace({'LL.B': 'LLB'})\n",
    "        df['Degree'] = df['Degree'].str.replace('.', '', regex=False).str.strip().str.upper()\n",
    "\n",
    "    # Fill whitespace\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col] = df[col].str.strip()\n",
    "\n",
    "    # Drop 'id' if present\n",
    "    if 'id' in df.columns:\n",
    "        df = df.drop(columns=['id'])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def custom_impute(df):\n",
    "    mask_student = (df['Working Professional or Student'] == 'Student') & (df['Profession'].isna())\n",
    "    df.loc[mask_student, 'Profession'] = 'Student'\n",
    "    mask_working = (df['Working Professional or Student'] == 'Working Professional') & (df['Profession'].isna())\n",
    "    df.loc[mask_working, 'Profession'] = 'Unknown'\n",
    "\n",
    "    median_student_pressure = df.loc[df['Working Professional or Student'] == 'Student', 'Academic Pressure'].median()\n",
    "    mask_student_nan = (df['Working Professional or Student'] == 'Student') & (df['Academic Pressure'].isna())\n",
    "    df.loc[mask_student_nan, 'Academic Pressure'] = median_student_pressure\n",
    "    mask_working_nan = (df['Working Professional or Student'] == 'Working Professional') & (df['Academic Pressure'].isna())\n",
    "    df.loc[mask_working_nan, 'Academic Pressure'] = 0\n",
    "\n",
    "    median_work_pressure = df.loc[df['Working Professional or Student'] == 'Working Professional', 'Work Pressure'].median()\n",
    "    mask_nan_working = (df['Working Professional or Student'] == 'Working Professional') & (df['Work Pressure'].isna())\n",
    "    df.loc[mask_nan_working, 'Work Pressure'] = median_work_pressure\n",
    "    mask_nan_students = (df['Working Professional or Student'] == 'Student') & (df['Work Pressure'].isna())\n",
    "    df.loc[mask_nan_students, 'Work Pressure'] = 0\n",
    "\n",
    "    median_cgpa_students = df.loc[df['Working Professional or Student'] == 'Student', 'CGPA'].median()\n",
    "    mask_student_cgpa_nan = (df['Working Professional or Student'] == 'Student') & (df['CGPA'].isna())\n",
    "    df.loc[mask_student_cgpa_nan, 'CGPA'] = median_cgpa_students\n",
    "    mask_working_cgpa_nan = (df['Working Professional or Student'] == 'Working Professional') & (df['CGPA'].isna())\n",
    "    df.loc[mask_working_cgpa_nan, 'CGPA'] = 0\n",
    "\n",
    "    median_study_satisfaction_students = df.loc[df['Working Professional or Student'] == 'Student', 'Study Satisfaction'].median()\n",
    "    mask_student_study_nan = (df['Working Professional or Student'] == 'Student') & (df['Study Satisfaction'].isna())\n",
    "    df.loc[mask_student_study_nan, 'Study Satisfaction'] = median_study_satisfaction_students\n",
    "    mask_working_study_nan = (df['Working Professional or Student'] == 'Working Professional') & (df['Study Satisfaction'].isna())\n",
    "    df.loc[mask_working_study_nan, 'Study Satisfaction'] = 0\n",
    "\n",
    "    median_job_satisfaction_working = df.loc[df['Working Professional or Student'] == 'Working Professional', 'Job Satisfaction'].median()\n",
    "    mask_working_job_nan = (df['Working Professional or Student'] == 'Working Professional') & (df['Job Satisfaction'].isna())\n",
    "    df.loc[mask_working_job_nan, 'Job Satisfaction'] = median_job_satisfaction_working\n",
    "    mask_student_job_nan = (df['Working Professional or Student'] == 'Student') & (df['Job Satisfaction'].isna())\n",
    "    df.loc[mask_student_job_nan, 'Job Satisfaction'] = 0\n",
    "\n",
    "    for col in ['Dietary Habits', 'Degree']:\n",
    "        if col in df.columns and df[col].isnull().any():\n",
    "            df[col].fillna(df[col].mode().iloc[0], inplace=True)\n",
    "    if 'Financial Stress' in df.columns and df['Financial Stress'].isnull().any():\n",
    "        df['Financial Stress'].fillna(df['Financial Stress'].median(), inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def encode_and_align(df_train, df_test, categorical_cols, numerical_cols, log_transform_cols):\n",
    "    train_encoded = pd.get_dummies(df_train, columns=categorical_cols, drop_first=False)\n",
    "    test_encoded  = pd.get_dummies(df_test, columns=categorical_cols, drop_first=False)\n",
    "    train_cols = set(train_encoded.columns)\n",
    "    test_cols  = set(test_encoded.columns)\n",
    "    missing_in_test = train_cols - test_cols\n",
    "    extra_in_test = test_cols - train_cols\n",
    "    for col in missing_in_test:\n",
    "        test_encoded[col] = 0\n",
    "    test_encoded = test_encoded[[col for col in train_encoded.columns if col in test_encoded.columns]]\n",
    "    for col in log_transform_cols:\n",
    "        if col in train_encoded.columns:\n",
    "            train_encoded[col] = np.log1p(train_encoded[col])\n",
    "        if col in test_encoded.columns:\n",
    "            test_encoded[col] = np.log1p(test_encoded[col])\n",
    "    return train_encoded, test_encoded\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "# Main pipeline flow\n",
    "# ---------------------------------------\n",
    "\n",
    "categorical_cols = [\n",
    "    'Gender', 'City', 'Working Professional or Student', 'Profession',\n",
    "    'Dietary Habits', 'Degree', 'Have you ever had suicidal thoughts ?',\n",
    "    'Family History of Mental Illness', 'Sleep Duration'\n",
    "]\n",
    "numerical_cols = [\n",
    "    'Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction',\n",
    "    'Job Satisfaction', 'Work/Study Hours', 'Financial Stress'\n",
    "]\n",
    "log_transform_cols = ['Academic Pressure', 'CGPA', 'Study Satisfaction']\n",
    "\n",
    "df_train = pd.read_csv(r\"D:\\GUVI\\Mental_health_survey\\playground-series-s4e11\\train.csv\")\n",
    "df_test = pd.read_csv(r\"D:\\GUVI\\Mental_health_survey\\playground-series-s4e11\\test.csv\")\n",
    "\n",
    "# Save test IDs before cleaning or dropping 'id'\n",
    "test_ids = df_test[\"id\"].copy()\n",
    "\n",
    "df_train = clean_df(df_train, is_train=True)\n",
    "df_test = clean_df(df_test, is_train=False)\n",
    "\n",
    "df_train = custom_impute(df_train)\n",
    "df_test = custom_impute(df_test)\n",
    "\n",
    "if \"id\" in df_train.columns:\n",
    "    df_train = df_train.drop(columns=[\"id\"])\n",
    "\n",
    "if \"id\" in df_test.columns:\n",
    "    df_test = df_test.drop(columns=[\"id\"])\n",
    "\n",
    "y_train = df_train[\"Depression\"]\n",
    "X_train = df_train.drop(columns=[\"Depression\"])\n",
    "X_test = df_test.copy()\n",
    "\n",
    "X_train_encoded, X_test_encoded = encode_and_align(\n",
    "    X_train, X_test, categorical_cols, numerical_cols, log_transform_cols\n",
    ")\n",
    "\n",
    "# Train-validation split for evaluation\n",
    "X_tr_enc, X_val_enc, y_tr, y_val = train_test_split(\n",
    "    X_train_encoded, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_tr_scaled = scaler.fit_transform(X_tr_enc)\n",
    "X_val_scaled = scaler.transform(X_val_enc)\n",
    "X_test_scaled = scaler.transform(X_test_encoded)\n",
    "\n",
    "joblib.dump(scaler, \"scaler_pipeline.save\")\n",
    "\n",
    "# Model creation\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_tr_scaled.shape[1], activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=Adam(learning_rate=0.001),\n",
    "              metrics=[\"accuracy\", Precision(name='precision'), Recall(name='recall'), AUC(name='auc')])\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "model.fit(\n",
    "    X_tr_scaled, y_tr,\n",
    "    validation_data=(X_val_scaled, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=512,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.save('mental_health_survey_final_pipeline.keras')\n",
    "\n",
    "# Evaluate on validation set\n",
    "y_val_pred_prob = model.predict(X_val_scaled)\n",
    "y_val_pred = (y_val_pred_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Validation Precision:\", precision_score(y_val, y_val_pred))\n",
    "print(\"Validation Recall:\", recall_score(y_val, y_val_pred))\n",
    "print(\"Validation F1 Score:\", f1_score(y_val, y_val_pred))\n",
    "print(\"Validation Confusion Matrix:\\n\", confusion_matrix(y_val, y_val_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Predict and save submission\n",
    "y_pred_test = model.predict(X_test_scaled)\n",
    "y_pred_test_classes = (y_pred_test > 0.5).astype(int).flatten()\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'Depression': y_pred_test_classes\n",
    "})\n",
    "submission.to_csv('submission1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79f60c6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
